---
title: "Wrangling"
tutorial:
  id: "02-wrangling"
output:
  learnr::tutorial:
      progressive: true
      allow_skip: true
runtime: shiny_prerendered
description: "Chapter 2 tutorial"
---

<!-- Things to fix in this tutorial. -->

<!-- It is a bad idea to create a column called "type" since that is the name of an R function. -->

<!-- Don't use a random package like fueleconomy. We need to minimize the number of extra packages we use.  -->
<!-- Be careful about manipulating an object in place for no good reason. Example:  -->

<!-- lexus_1998 <- lexus_1998 %>% -->
<!--   rename("class" = type) -->

<!-- Even if you need a special object called lexus_1998, just create once. Key -->


```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(stringr)
library(learnr)
library(shiny)
library(PPBDS.data)
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
options(tutorial.exercise.timelimit = 60, tutorial.storage="local") 

# Set up stringr-objects
library(dslabs)
murders <- as_tibble(murders)
states <- murders$state
states2 <- murders %>%
  select(state, abb)

# Set up cars
# DK: Creating a column called "type" is a bad idea since it is an R function
# name. Also, why are we using this random R package?

library(fueleconomy)
lexus_2000 <- vehicles %>%
  filter(year == 2000,
         make == "Lexus") %>%
  select(id, make, model, class, drive)

lexus_1999 <- vehicles %>%
  filter(year == 1999,
         make == "Lexus") %>%
  select(id, make, model, class, trans, drive) 

lexus_1998 <- vehicles %>%
  filter(year == 1998,
         make == "Lexus") %>%
  select(id, make, model, class, trans, drive) %>%
  rename("type" = class)

lexus_mileage <- vehicles %>%
  filter(year == 2000,
         make == "Lexus") %>%
  select(id, hwy, cty) %>%
  slice(3:9)

# Needed for later sections of the tutorial 
library(fivethirtyeight)
library(nycflights13)
library(ggthemes)
```

## Introduction 

``` {r name, echo=FALSE}
question_text(
  "Student Name:",
  answer(NULL, correct = TRUE),
  incorrect = "Ok",
  try_again_button = "Modify your answer",
  allow_retry = TRUE
)
```

## Characters 
Use `str_detect()` on `states` to find state that contain the pattern "ana":
```{r exercise-2-1, exercise=TRUE}

```

```{r exercise-2-1-hint, eval=FALSE}
str_detect(..., pattern = ...)
```

Now use `str_subset()` with `states` to find the names of the states that contain the pattern "ana" instead of just the boolean values: 
```{r exercise-2-2, exercise=TRUE}

```

```{r exercise-2-2-hint, eval=FALSE}
str_subset(..., pattern = ...)
```

Use `str_subset()` to find `states` that have two a's in their name:
```{r exercise-2-3, exercise=TRUE}

```

```{r exercise-2-3-hint-1, eval=FALSE}
# Considering use the regex "."
```

```{r exercise-2-3-hint-2, eval=FALSE}
str_subset(..., pattern = ...)
```

`str_split()` `states` that are two or more words:
```{r exercise-2-4, exercise=TRUE}

```

```{r exercise-2-4-hint, eval=FALSE}
str_split(..., pattern = ...)
```

`str_split_fixed()` `states` into two words. What will happen to `District of Columbia`?
```{r exercise-2-5, exercise=TRUE}

```

```{r exercise-2-5-hint, eval=FALSE}
str_split_fixed(..., pattern = ..., n = ...)
```

Collapse `states` using `str_c()`, and separate them with a comma.
```{r exercise-2-6, exercise=TRUE}

```

```{r exercise-2-6-hint, eval=FALSE}
str_c(states, collapse = ",")
```

Use `str_c` to collapse states into the form `state1 & state2`. Combine the first 1-25 states with states 26-50. Note that we have to exclude the 51st state.
```{r exercise-2-7, exercise=TRUE}

```

```{r exercise-2-7-hint, eval=FALSE}
str_c(..., ..., sep = ...)
```

Use `str_replace()` to replace the pattern `North` with `N.`. For example, transform North Carolina into N. Carolina.
```{r exercise-2-8, exercise=TRUE}

```

```{r exercise-2-8-hint, eval=FALSE}
str_replace(..., pattern = ..., replacement = ...)
```

Use `str_subset()` to find `states` that contain the letter a and then one or more characters and another a.
```{r exercise-2-9, exercise=TRUE}

```

```{r exercise-2-9-hint-1, eval=FALSE}
# Consider using the pattern "a.*a"
```

```{r exercise-2-9-hint-2, eval=FALSE}
str_subset(..., pattern = ...)
```

Does capitalization matter? Repeat the previous question but replace the first letter with a capital "A". 
```{r exercise-2-10, exercise=TRUE}

```

```{r exercise-2-10-hint, eval=FALSE}
str_subset(..., pattern = ...)
```

`glimpse()` the `states2` tibble. 
```{r exercise-2-11, exercise=TRUE}

```

```{r exercise-2-11-hint, eval=FALSE}
glimpse(states2)
```

`mutate()` the `states2` dataset so that it contains a column `state_length` that takes the `str_length()` of each `state`. Then, `arrange()` the dataset from the state with the longest name to that with the shortest.
```{r exercise-2-12, exercise=TRUE}

```

```{r exercise-2-12-hint, eval=FALSE}
states2 %>% 
  mutate(... = str_length(...)) %>%
  arrange(desc(...))
```

Now compare the previous question by the `states2` dataset arranged by `desc(state)`. How does this arrangement differ from the previous one?
```{r exercise-2-13, exercise=TRUE}

```

```{r exercise-2-13-hint, eval=FALSE}
... %>% 
  arrange(desc(...))
```

`mutate()` the `state` column of `states2` to only contain the first two letters of each state name. Reassign this as `states2`.
```{r exercise-2-14, exercise=TRUE}

```

```{r exercise-2-14-hint-1, eval=FALSE}
... <- states2 %>% mutate(... = str_sub(...))
```

```{r exercise-2-15-setup}
states2 <- states2 %>%
  mutate(state = str_sub(state, 1, 2))
```

Now use `str_to_upper()` and `mutate()` to make both of the first two letters of the states capital letters. Reassign this as `states2`.
```{r exercise-2-15, exercise=TRUE}

```

```{r exercise-2-15-hint, eval=FALSE}
... <- states2 %>% mutate(... = str_to_upper(...))
```

```{r exercise-2-16-setup}
states2 <- states2 %>% 
  mutate(state = str_sub(state, 1, 2)) %>% 
  mutate(state = str_to_upper(state))
```

`mutate()` a new column called `match` that creates a TRUE or FALSE value if the first two letters of the state name (the `state` column) and the `abb` column match.
```{r exercise-2-16, exercise=TRUE}

```

```{r exercise-2-16-hint, eval=FALSE}
states2 %>% mutate(match = (... == ...))
```

```{r exercise-2-17-setup}
states2 <- states2 %>%
  mutate(state = str_sub(state, 1, 2)) %>% 
  mutate(state = str_to_upper(state)) %>%
  mutate(match = (state == abb))
```
`count()` the `match` column.
```{r exercise-2-17, exercise=TRUE}

```

```{r exercise-2-17-hint, eval=FALSE}
states2 %>% count(...)
```

```{r exercise-2-17-quiz}
quiz(
  question("How many state abbreviations match the first two letters of the state's name?",
    answer("15"),
    answer("42"),
    answer("23"),
    answer("32", correct = TRUE),
    allow_retry = TRUE
  )
)
```

## Factors 

## Lists

## Date-Times 

## Combining Data

### bind_rows()
### Exercise 1

Run `lexus_2000` in this code chunk:
```{r exercise-combining-1, exercise=TRUE}

```

```{r exercise-combining-1-hint, eval=FALSE}
lexus_2000
```

### Exercise 2
Run `lexus_1999` in the code chunk: 
```{r exercise-combining-2, exercise=TRUE}

```

```{r exercise-combining-2-hint, eval=FALSE}
lexus_1999
```

```{r quiz-combining-2}
quiz(
  question("Which variable is included in lexus_1999 but not lexus_2000",
    answer("id"),
    answer("make"),
    answer("model"),
    answer("class"),
    answer("trans", correct = TRUE),
    answer("drive"),
    allow_retry = TRUE
  )
)
```
What do you think will happen we try to bind the rows? 

### Exercise 3

Use `bind_rows()` to bind `lexus_1999` and `lexus_2000`:
What happens to the `trans` column?
```{r question-combining-3, exercise=TRUE}

```

```{r question-combining-3-hint, eval=FALSE}
bind_rows(..., ...)
```

### Exercise 4 

Run `lexus_1998` in the following code chunk:
```{r question-combining-4, exercise=TRUE}

```
What is the discrepancy between the columns of `lexus_1998` and `lexus_1999`. How do you think this will affect binding the rows of the two dataframes?

### Exercise 5

Bind the two dataframes `lexus_1998` and `lexus_1999`:
```{r question-combining-5, exercise=TRUE}
bind_rows(lexus_1998, lexus_1999)
```

```{r question-combining-5-hint, eval=FALSE}
bind_rows(..., ...)
```

### Exercise 6

Use the `rename()` function to change the `type` variable to `class` in the `lexus_1998` dataframe. Use the assignment operator to reassign the changed dataframe to `lexus_1998`. 
```{r question-combining-6, exercise=TRUE}

```

```{r question-combining-6-hint, eval=FALSE}
... <- ... %>%
  rename(...)
```

### Exercise 7

Use `bind_rows` to bind `lexus_1998` and `lexus_1999` again. Assign this dataframe as `lexus_two_year`: 
```{r question-combining-7, exercise=TRUE}

```

```{r question-combining-7-hint, eval=FALSE}
... <- bind_rows(..., ...)
```

### Exercise 8

```{r question-combining-8-setup}
lexus_1998 <- lexus_1998 %>%
  rename("class" = type)
lexus_two_year <- bind_rows(lexus_1998, lexus_1999)
```
Now bind the rows of `lexus_two_year` with `lexus_2000`. Use the assignment operator to call this dataframe `lexus`
```{r question-combining-8, exercise=TRUE}

```

```{r question-combining-8-hint, eval=FALSE}
... <- bind_rows(..., ...)
```

### Exercise 9

```{r question-combining-9-setup}
lexus_two_year <- bind_rows(lexus_1998, lexus_1999)
lexus <- bind_rows(lexus_two_year, lexus_2000)
```

Now, `unite()` the `make` and `model` columns of the `lexus` dataframe. Name this united column `vehicle`, and make the separator between the previous columns a space.
```{r question-combining-1, exercise=TRUE}

```

```{r question-combining-9-hint-1, eval=FALSE}
lexus %>%
  unite(..., ..., ..., sep = ...)
```

```{r question-combining-9-hint-2, eval=FALSE}
lexus %>%
  unite("vehicle", ..., ..., sep = " ")
```

### joins in dplyr

### Exercise 10 

Let's return to the `lexus_2000` data. `glimpse()` both the `lexus_2000` dataframe and the `lexus_mileage` dataframe.
```{r question-combining-10, exercise=TRUE}

```

```{r question-combining-10-hint, eval=FALSE}
glimpse(... )

glimpse(...)
```

### Exercise 11

Now use the extraction operator `$` on the `id` columns of both `lexus_2000` and `lexus_mileage`.
```{r question-combining-11, exercise=TRUE}

```

```{r question-combining-11-hint, eval=FALSE}
lexus_2000$...

lexus_mileage$...
```

```{r question-combining-11-quiz}
quiz(
  question("Which id(s) are included in the lexus_2000 dataframe but not in the lexus_mileage dataframe?",
    answer("16365, 16366"),
    answer("15921, 15922, 16038, 16366, 16039, 15685, 15686"),
    answer("15801"),
    answer("15920, 15801", correct = TRUE),
    answer("15801, 15920, 15921"),
    answer("15685, 16039"),
    allow_retry = TRUE
  )
)
```

### Exercise 12
```{r question-combining-12-quiz}
quiz(
  question("Which id(s) will be excluded when you full_join() both datasets?",
    answer("None", correct = TRUE),
    answer("16365, 16366"),
    answer("15920, 15801"),
    answer("15801, 15922"),
    allow_retry = TRUE
  )
)
```

`full_join()` the `lexus_2000` and `lexus_mileage` dataframes by the `id` columns. Visually confirm your answer to the question above.
```{r question-combining-12, exercise=TRUE}

```

```{r question-combining-12-hint, eval=FALSE}
full_join(..., ..., by = ...)
```

### Exercise 13 
```{r question-combining-13-quiz}
quiz(
  question("Which id(s) will be excluded when you inner_join() both datasets?",
    answer("None"),
    answer("16365, 16366"),
    answer("15920, 15801", correct = TRUE),
    answer("15801, 15922"),
    allow_retry = TRUE
  )
)
```
`inner_join()` the `lexus_2000` and `lexus_mileage` dataframes by the `id` columns. Visually confirm your answer to the question above.
```{r question-combining-13, exercise=TRUE}

```

```{r question-combining-13-hint, eval=FALSE}
inner_join(..., ..., by = ...)
```

### Exercise 14
```{r question-combining-14-1-quiz}
quiz(
  question("Which id(s) will be excluded when you run left_join(lexus_2000, lexus_mileage, by = 'id')?",
    answer("None", correct = TRUE),
    answer("All"),
    answer("15920, 15801"),
    answer("15801, 15922"),
    allow_retry = TRUE
  )
)

```

```{r question-combining-14-2-quiz}
quiz(
  question("Which id(s) will be excluded when you run left_join(lexus_mileage, lexus_2000)?",
    answer("None"),
    answer("All"),
    answer("15920, 15801", correct = TRUE),
    answer("15801, 15922"),
    allow_retry = TRUE
  )
)
```

```{r question-combining-14-3-quiz}
quiz(
  question("Which id(s) will be excluded when you run left_join(lexus_mileage, lexus_2000, by = 'id')?",
    answer("None"),
    answer("All"),
    answer("15920, 15801", correct = TRUE),
    answer("15801, 15922"),
    allow_retry = TRUE
  )
)
```

```{r question-combining-14-4-quiz}
quiz(
  question("Which id(s) will be excluded when you run right_join(lexus_2000, lexus_mileage, by = 'id')?",
    answer("None"),
    answer("All"),
    answer("15920, 15801", correct = TRUE),
    answer("15801, 15922"),
    allow_retry = TRUE
  )
)
```

```{r question-combining-14-5-quiz}
quiz(
  question("Which id(s) will be excluded when you run right_join(lexus_mileage, lexus_2000, by = 'id')?",
    answer("None", correct = TRUE),
    answer("All"),
    answer("15920, 15801"),
    answer("15801, 15922"),
    allow_retry = TRUE
  )
)
```

```{r question-combining-14-6-quiz}
quiz(
  question("Which id(s) will be excluded when you run anti_join(lexus_mileage, lexus_2000, by = 'id')?",
    answer("None"),
    answer("All", correct = TRUE),
    answer("15920, 15801"),
    answer("15801, 15922"),
    allow_retry = TRUE
  )
)
```

```{r question-combining-14-7-quiz}
quiz(
  question("Which id(s) will be excluded when you run anti_join(lexus_2000, lexus_mileage, by = 'id')?",
    answer("None"),
    answer("All"),
    answer("15920, 15801", correct = TRUE),
    answer("15801, 15922"),
    allow_retry = TRUE
  )
)
```

```{r question-combining-14-8-quiz}
quiz(
  question("Which columns will be excluded when you run semi_join(lexus_2000, lexus_mileage, by = 'id')?",
    answer("id, hwy, cty"),
    answer("hwy, cty", correct = TRUE),
    answer("id, class, drive"),
    answer("id, make, model, class, drive"),
    allow_retry = TRUE
  )
)
```

```{r question-combining-14-9-quiz}
quiz(
  question("Which columns will be excluded when you run semi_join(lexus_mileage, lexus_2000, by = 'id')?",
    answer("id, hwy, cty"),
    answer("hwy, cty"),
    answer("id, class, drive"),
    answer("make, model, class, drive", correct = TRUE),
    allow_retry = TRUE
  )
)
```

## Tidying Data

### Exercise 1
Run `table1` in the code chunk below:
```{r question-tidying-1, exercise=TRUE}

```

```{r question-tidying-1-solution}
table1
```

```{r question-tidying-1-quiz}
quiz(
  question("Is table1 in tidy format?",
  answer("Yes", correct = TRUE),
  answer("No"),
  allow_retry = TRUE
)
)

```

### Exercise 2
Now, run `table2` in the code chunk below:
```{r question-tidying-2, exercise=TRUE}

```

```{r question-tidying-2-solution}
table2
```

```{r question-tidying-2-quiz}
quiz(
  question("Is table2 in tidy format?",
  answer("Yes"),
  answer("No", correct = TRUE),
  allow_retry = TRUE
)
)
```

### Exercise 3 
Use `pivot_longer()` to put `table1` into untidy format.
```{r question-tidying-3, exercise=TRUE}

```

```{r question-tidying-3-hint, eval=FALSE}
... %>%
  pivot_longer(cols = ..., names_to = ..., values_to = ...)
```

### Exercise 4 

Use `pivot_wider()` to put `table2` into tidy format.
```{r question-tidying-4, exercise=TRUE}

```

```{r question-tidying-4-hint, eval=FALSE}
... %>%
  pivot_wider(names_from = ..., values_from = ...)
```

## National Health and Nutrition Survey

`nhanes` is a dataset included in the Five Thirty Eight data package. This dataset was referenced in Five Thirty Eight's article ["Don't Take Your] Vitamins" (https://fivethirtyeight.com/features/dont-take-your-vitamins/) and was take from the "National Health and Nutrition Examination Survey," which contains the personal and physical information of 10,000 Americans from two surveys in 2009 and 2011.

### Exercise 1
Begin by running `summary()` on `nhanes`. Based on the results, try to guess what the units of measurement are for the `weight` and `height` variables.

```{r nhanes1, exercise = TRUE}

```

### Exercise 2

In the original tibble, `weight` is measured in kg and `height` in cm. Using `mutate()`, multiply `weight` by 2.2 and divide `height` by 30.48 to convert units into pounds and feet. Use this assignment operator to name this mutated tibble `nhanes_imperial`. 

```{r nhanes2, exercise = TRUE}

```

```{r nhanes2-hint, eval = FALSE}
nhanes_imperial <- nhanes %>%
  mutate(weight = ..., height = ...)
```

### Exercise 3

`select()` the `gender`, `weight`, `height`, and `bmi` columns from the `nhanes_imperial` tibble. Reassign this as `nhanes_imperial`. 

```{r nhanes3-setup}
nhanes_imperial <- nhanes %>%
  mutate(weight = weight * 2.2, height = height / 30.48)

```

```{r nhanes3, exercise = TRUE}

```

```{r nhanes3-hint, eval=FALSE}
nhanes_imperial <- nhanes_imperial %>%
  select(..., ..., ..., ...)
```

### Exercise 4

Use tidyr's `drop_na()` to remove all rows with a value of `NA` in either the `weight` or `height` columns. Reassign this as `nhanes_imperial`, so it will be saved. 

```{r nhanes4-setup}
nhanes_imperial <- nhanes %>%
  mutate(weight = weight * 2.2, height = height / 30.48) %>%
  select(gender, weight, height, bmi)
```

```{r nhanes4, exercise = TRUE, exercise.lines = 4}

```

```{r nhanes4-hint, eval = FALSE}
nhanes_imperial <- nhanes_imperial %>%
  drop_na(..., ...)
```

### Exercise 5

Call `ggplot()` to make a jittered scatterplot that maps `weight` to the x-axis, `height` to the y-axis, and `bmi` to the color aesthetic. Names this plot `nhanes_plot`. 

```{r nhanes5-setup}
nhanes_imperial <- nhanes %>%
  mutate(weight = weight * 2.2, height = height / 30.48) %>%
  select(gender, weight, height, bmi) %>%
  drop_na(weight, height)
```

```{r nhanes5, exercise = TRUE}

```

```{r nhanes5-hint-1}
# Remember to use geom_jitter().
```

```{r nhanes5-hint-2, eval=FALSE}
nhanes_plot <- ggplot(data = ..., aes(x = ..., y = ..., color = ...))
```

### Exercise 6

Add a trend line layer to your plot with `geom_smooth()`. Change the `se` argument of `geom_smooth()` to remove the confidence interval, and change the `color` of the line to "dodgerblue." Be sure to reassign this changed plot to the object name `nhanes_plot`. 

```{r nhanes6-setup}
nhanes_imperial <- nhanes %>%
  mutate(weight = weight * 2.2, height = height / 30.48) %>%
  select(gender, weight, height, bmi) %>%
  drop_na(weight, height) 
nhanes_plot <- ggplot(data = nhanes_imperial, 
                      mapping = aes(x = weight, y = height, color = bmi)) +
    geom_jitter()
```

```{r nhanes6, exercise = TRUE}

```

```{r nhanes6-hint-1}
# The se argument should be equal to FALSE.
```

```{r nhanes6-hint-2, eval=FALSE}
nhanes_plot <- nhanes_plot + 
  geom_smooth(se = ..., color = ...)
```

### Exercise 7

Use `facet_wrap()` to facet the `nhanes_plot` graph by `gender`.

```{r nhanes7-setup}
nhanes_imperial <- nhanes %>%
  mutate(weight = weight * 2.2, height = height / 30.48) %>%
  select(gender, weight, height, bmi) %>%
  drop_na(weight, height) 
nhanes_plot <- ggplot(data = nhanes_imperial, 
                      mapping = aes(x = weight, y = height, color = bmi)) +
    geom_jitter() +
    geom_smooth(se = FALSE, color = "dodgerblue")
```

```{r nhanes7, exercise = TRUE}

```

```{r nhanes7-hint, eval=FALSE}
nhanes_plot <- nhanes_plot +
  facet_wrap(...)
```


### Exercise 8

Finally, adjust the feel of the graph with `theme_clean()` from the **ggthemes** package. Make sure you have this package loaded, or you will be unable to run the code chunk. 

```{r nhanes8-setup}
nhanes_imperial <- nhanes %>%
  mutate(weight = weight * 2.2, height = height / 30.48) %>%
  select(gender, weight, height, bmi) %>%
  drop_na(weight, height) 

nhanes_plot <- ggplot(data = nhanes_imperial, 
                      mapping = aes(x = weight, y = height, color = bmi)) +
    geom_jitter() +
    geom_smooth(se = FALSE, color = "dodgerblue") +
    facet_wrap(~ gender)
```

```{r nhanes8, exercise = TRUE}

```

```{r nhanes8-hint, eval=FALSE}
nhanes_plot <- nhanes_plot +
  ...
```

### Exercise 9

Great work! From this graph, we can see that children of both genders tend to grow very quickly without gaining much weight (this is the very steep slope at the beginning of the two graphs). However, after people reach between 100-120 pounds, weight gain becomes coupled with a substantially smaller increase in height. Additionally, both weight and height seem to be higher for males than for females on average. Finally, we can infer from looking at the color gradient that a high `bmi` (i.e. brighter colors) corresponds with higher weight and lower height.

To finish your plot, use `labs()` to give the graph a title and subtitle of your choice.

```{r nhanes9-setup}
nhanes_imperial <- nhanes %>%
  mutate(weight = weight * 2.2, height = height / 30.48) %>%
  select(gender, weight, height, bmi) %>%
  drop_na(weight, height)

nhanes_plot <- ggplot(data = nhanes_imperial, 
                      mapping = aes(x = weight, y = height, color = bmi)) +
  geom_jitter() +
  geom_smooth(se = FALSE, color = "dodgerblue") +
  facet_wrap(~ gender) + 
  theme_clean()
```

```{r nhanes9, exercise = TRUE}

```

```{r nhanes9-hint, eval = FALSE}
nhanes_plot +
  labs(title = ..., subtitle = ...)
```

## Kenya Dataset

The `kenya` data set (from the `PPBDS.data` package) records the data from a study in which poll stations in Kenya were assigned to either the control group or a group in which one or more methods were used to encourage voter registration (an SMS reminder, canvassing, etc.)

### Exercise 1

Start by `glimpse()`ing the `kenya` data set.

```{r kenya1-setup}
PPBDS.data::kenya
```

```{r kenya1, exercise = TRUE}

```

```{r kenya1-hint}
glimpse(kenya)
```

### Exercise 2

Pipe `kenya` into the `count()` function to count the number of poll stations in each `treatment` group.

```{r kenya2-setup}
PPBDS.data::kenya
```

```{r kenya2, exercise = TRUE}

```

```{r kenya2-hint, eval = FALSE}
kenya %>%
  count(...)
```

### Exercise 3

Using a pipe and the `%in%` operator, `filter()` `kenya` to only the rows with a `treatment` of "control," "local," "SMS," or "canvass." Assign this new dataframe to `kenya_subset`.

```{r kenya3-setup}
PPBDS.data::kenya
```

```{r kenya3, exercise = TRUE}

```

```{r kenya3-hint-1, eval=FALSE}
... <- kenya %>%
  filter(treatment %in% ...)
```

```{r kenya3-hint-2, eval=FALSE}
kenya_subset <- kenya %>%
  filter(treatment %in% c(...))
```

### Exercise 4

Because `treatment` is a factor, call `droplevels()` immediately after the `filter()` call to avoid future complications. Reassign this as `kenya_subset`. 

```{r kenya4-setup}
kenya_subset <- kenya %>% 
  filter(treatment %in% c("control", "local", "SMS", "canvass"))
```

```{r kenya4, exercise = TRUE}

```

```{r kenya4-hint, eval=FALSE}
kenya_subset <- kenya_subest %>%
  ...
```

### Exercise 5 

`select()` the `treatment`, `mean_age`, and `reg_byrv13` columns in `kenya_subset`. Don't forget to re-save this as `kenya_subset`. 

```{r kenya5-setup}
kenya_subset <- kenya %>%
  filter(treatment %in% c("control", "local", "SMS", "canvass")) %>%
  droplevels()
```

```{r kenya5, exercise = TRUE}

```

```{r kenya5-hint, eval=FALSE}
kenya_subset <- kenya_subset %>%
  select(...)
```

### Exercise 6

Use tidyr's `drop_na()` to remove all rows with a value of `NA` in the `mean_age` column. Reassign this as `kenya_subset`. 

```{r kenya6-setup}
kenya_subset <- kenya %>%
  filter(treatment %in% c("control", "local", "SMS", "canvass")) %>%
  droplevels() %>%
  select(treatment, mean_age, reg_byrv13)
```

```{r kenya6, exercise = TRUE}

```

```{r kenya6-hint, eval = FALSE}
kenya_subset <- kenya_subset %>%
  drop_na(...)
```

### Exercise 7

The dplyr `ntile()` function divides a continuous numerical value into categories depending on its size. Try running the following code to see how we can categorize the polling stations into 4 equally-sized groups based on the `distance` to the polling station.

```{r kenya7-setup}
PPBDS.data::kenya
```

```{r kenya7, exercise = TRUE}
kenya %>%
  mutate(distance_quartile = ntile(distance, 4))
```

### Exercise 8 

Use `mutate()` and `ntile()` to create the variable `age_half`, which categorizes the `mean_age` variable into 2 groups: the younger half, and the older half.

```{r kenya8-setup}
kenya_subset <- kenya %>%
  filter(treatment %in% c("control", "local", "SMS", "canvass")) %>%
  droplevels() %>%
  select(treatment, mean_age, reg_byrv13) %>%
  drop_na(mean_age)
```

```{r kenya8, exercise = TRUE}

```

```{r kenya8-hint}
# ntile(mean_age, 2) will categorize age into the younger half and the older half.
```

### Exercise 9

Group the data by `treatment` and `age_half`.

```{r kenya9-setup}
kenya_subset <- kenya %>%
  filter(treatment %in% c("control", "local", "SMS", "canvass")) %>%
  droplevels() %>%
  select(treatment, mean_age, reg_byrv13) %>%
  drop_na(mean_age) %>%
  mutate(age_half = ntile(mean_age, 2))
```

```{r kenya9, exercise = TRUE}

```

```{r kenya9-hint, eval=FALSE}
kenya_subset <- kenya_subset %>%
  group_by(...)
```

### Exercise 10

Using `summarize()`, calculate the variable `mean_turnout` as the average value of `reg_byrv13` in each group. Remember to set the `na.rm` argument of `mean()` to `TRUE`, as there are some `NA` values in the `reg_byrv13` column.

```{r kenya10-setup}
kenya_subset <- kenya %>%
  filter(treatment %in% c("control", "local", "SMS", "canvass")) %>%
  droplevels() %>%
  select(treatment, mean_age, reg_byrv13) %>%
  drop_na(mean_age) %>%
  mutate(age_half = ntile(mean_age, 2)) %>%
  group_by(treatment, age_half)
```

```{r kenya10, exercise = TRUE}

```

```{r kenya10-hint, eval = FALSE}
kenya_subset <- kenya_subset %>%
  summarize(mean_turnout = ...)
```

### Exercise 11 

Create a `ggplot()` named `kenya_plot` that makes a bar graph with `treatment` on the x-axis and `mean_turnout` on the y-axis.

```{r kenya11-setup}
kenya_subset <- kenya %>%
  filter(treatment %in% c("control", "local", "SMS", "canvass")) %>%
  droplevels() %>%
  select(treatment, mean_age, reg_byrv13) %>%
  drop_na(mean_age) %>%
  mutate(age_half = ntile(mean_age, 2)) %>%
  group_by(treatment, age_half) %>%
  summarize(mean_turnout = mean(reg_byrv13, na.rm = TRUE))
```

```{r kenya11, exercise = TRUE}

```

```{r kenya11-hint, eval=FALSE}
kenya_plot <- ggplot(data = ..., aes(x = ..., y = ...)) +
  ...
```

```{r kenya11-hint-2}
# Remember to use geom_col() instead of geom_bar() when you map something to the y-axis.
```

### Exercise 12 

Already, we can see that one of the treatments is significantly more effective at increasing turnout than others. Continue by using `facet_wrap()` to facet the data by `age_half`. Don't forget to reassign this as `kenya_plot`. 

```{r kenya12-setup}
kenya_subset <- kenya %>%
  filter(treatment %in% c("control", "local", "SMS", "canvass")) %>%
  droplevels() %>%
  select(treatment, mean_age, reg_byrv13) %>%
  drop_na(mean_age) %>%
  mutate(age_half = ntile(mean_age, 2)) %>%
  group_by(treatment, age_half) %>%
  summarize(mean_turnout = mean(reg_byrv13, na.rm = TRUE))

kenya_plot <- ggplot(data = kenya_subset, 
                     mapping = aes(x = treatment, y = mean_turnout)) +
    geom_col()
```

```{r kenya12, exercise = TRUE}

```

```{r kenya12-hint, eval=FALSE}
kenya_plot <- kenya_plot +
  facet_wrap(~ ...)
```


### Exercise 13

To make the graph easier to read, use `fct_reorder()` to reorder the `treatment` variable by `mean_turnout`. Call this new plot `kenya_plot_2`. Note, you will no longer use the `facet_wrap()`, as this will cause issues with the ordering of the `treatment` categories.

```{r kenya13-setup}
kenya_subset <- kenya %>%
  filter(treatment %in% c("control", "local", "SMS", "canvass")) %>%
  droplevels() %>%
  select(treatment, mean_age, reg_byrv13) %>%
  drop_na(mean_age) %>%
  mutate(age_half = ntile(mean_age, 2)) %>%
  group_by(treatment, age_half) %>%
  summarize(mean_turnout = mean(reg_byrv13, na.rm = TRUE))
```

```{r kenya13, exercise = TRUE}

```

```{r kenya13-hint, eval = FALSE}
kenya_plot_2 <- ggplot(data = ..., mapping = aes(x = fct_reorder(..., ...), y = ...)) +
    geom_col()
```

### Exercise 14

Improve the aesthetics of the graph by changing the theme to `theme_bw()`.

```{r kenya14-setup}
kenya_subset <- kenya %>%
  filter(treatment %in% c("control", "local", "SMS", "canvass")) %>%
  droplevels() %>%
  select(treatment, mean_age, reg_byrv13) %>%
  drop_na(mean_age) %>%
  mutate(age_half = ntile(mean_age, 2)) %>%
  group_by(treatment, age_half) %>%
  summarize(mean_turnout = mean(reg_byrv13, na.rm = TRUE))

kenya_plot_2 <- ggplot(data = kenya_subset,
                       mapping = aes(x = fct_reorder(treatment, mean_turnout), y = mean_turnout)) +
    geom_col()
```

```{r kenya14, exercise = TRUE}

```

```{r kenya14-hint, eval=FALSE}
kenya_plot_2 <- kenya_plot_2 +
  ...
```

### Exercise 15

Great job! This graph allows us to see that the presence of a local administrator at the polling location is by far the most effective strategy for increasing voter turnout. In addition, older voters (category 2) are not only more likely to vote than younger voters, but they are also influenced to a greater extent by the presence of a local administrator.

To finish your plot, use `labs()` to change the x-axis label to "treatment." In addition, give the graph a title and subtitle of your choosing.

```{r kenya15-setup}
kenya_subset <- kenya %>%
  filter(treatment %in% c("control", "local", "SMS", "canvass")) %>%
  droplevels() %>%
  select(treatment, mean_age, reg_byrv13) %>%
  drop_na(mean_age) %>%
  mutate(age_half = ntile(mean_age, 2)) %>%
  group_by(treatment, age_half) %>%
  summarize(mean_turnout = mean(reg_byrv13, na.rm = TRUE))

kenya_plot_2 <- ggplot(data = kenya_subset,
                       mapping = aes(x = fct_reorder(treatment, mean_turnout), y = mean_turnout)) +
    geom_col() +
    theme_bw()
```

```{r kenya15, exercise = TRUE}

```

```{r kenya15-hint, eval=FALSE}
kenya_plot_2 + 
    labs(...)
```

## Seguro Popular
### Exercise 1 

The `sps` data set from the PPBDS.data pakcage contains information about a study done on a popular Mexican health insurance program, Seguro Popular. In the study, some Mexican health clusters were randomly "treated." The treatment consisted of encouragement for people in that health cluster to enroll in the health insurance program, as well as funds to improve health facilities in the cluster.

Start by calling `glimpse()` on `sps`.

```{r sps1-setup}
PPBDS.data::sps
```

```{r sps1, exercise = TRUE}

```

```{r sps1-hint, eval=FALSE}
glimpse(...)
```

### Exercise 2

Using a pipe and the `%in%` operator, `filter()` `sps` to the observations with an `education` of "preschool," "secondary," "high school," or "college." Save this new dataset as `sps_subset`.

```{r sps2-setup}
PPBDS.data::sps
```

```{r sps2, exercise = TRUE}

```

```{r sps2-hint-1, eval=FALSE}
... <- sps %>%
  filter(education %in% ...)
```

```{r sps2-hint-2, eval=FALSE}
... <- sps %>% 
  filter(education %in% c(...))
```

### Exercise 3

Use `select()` to remove the columns `health_exp_1m` and `t2_health_exp_1m` (these measure health expenses over the past month, whereas `health_exp_3m` and `t2_health_exp_3m` measure health expenses over the past 3 months). Resave this as `sps_subset`.

```{r sps3-setup}
sps_subset <- sps %>%
  filter(education %in% c("preschool", "secondary", "high school", "college"))
```

```{r sps3, exercise = TRUE}

```

```{r sps3-hint-1}
# Remember that select(-column_name) returns all columns except for that column.
```

```{r sps3-hint-2}
# Consider using c()
```


### Exercise 4 

`mutate()` a new variable, `change_in_expenses`, equal to `health_exp_3m` subtracted from `t2_health_exp_3m` (this measures the change in expenses after the treatment period). Resave this as `sps_subset`.

```{r sps4-setup}
sps_subset <- sps %>%
  filter(education %in% c("preschool", "secondary", "high school", "college")) %>%
  select(-c(health_exp_1m, t2_health_exp_1m))
```

```{r sps4, exercise = TRUE}

```

### Exercise 5

Group the data by `treatment` and `education`.

```{r sps5-setup}
sps_subset <- sps %>%
  filter(education %in% c("preschool", "secondary", "high school", "college")) %>%
  select(-c(health_exp_1m, t2_health_exp_1m)) %>% 
  mutate(change_in_expenses = t2_health_exp_3m - health_exp_3m)
```

```{r sps5, exercise = TRUE}

```

```{r sps5-hint}
# Use the group_by() function.
```

### Exercise 6

Using `summarize()`, calculate `mean_change_in_expenses`, the average of the `change_in_expenses` for each group.

```{r sps6-setup}
sps_subset <- sps %>%
  filter(education %in% c("preschool", "secondary", "high school", "college")) %>%
  select(-c(health_exp_1m, t2_health_exp_1m)) %>% 
  mutate(change_in_expenses = t2_health_exp_3m - health_exp_3m) %>%
  group_by(treatment, education)
```

```{r sps6, exercise = TRUE}
  
```

```{r sps6-hint, eval = FALSE}
# Use the summarize() function and the helper function mean()
```

### Exercise 7

Call `ggplot()` to make a bar graph that maps `education` to the x-axis, `mean_change_in_expenses` to the y-axis, and `treatment` to the fill aesthetic. Call this plot `sps_plot`. 

```{r sps7-setup}
sps_subset <- sps %>%
  filter(education %in% c("preschool", "secondary", "high school", "college")) %>%
  select(-c(health_exp_1m, t2_health_exp_1m)) %>%
  mutate(change_in_expenses = t2_health_exp_3m - health_exp_3m) %>%
  group_by(treatment, education) %>%
  summarize(mean_change_in_expenses = mean(change_in_expenses))
```

```{r sps7, exercise = TRUE}

```

```{r sps7-hint}
# Remember to use geom_col() instead of geom_bar() when mapping a variable to the y-axis.
```

### Exercise 8 

Use the `position_dodge` function with `preserve` equal to "single" to create a dodged barplot. Does it work?

```{r sps8-setup}
sps_subset <- sps %>%
  filter(education %in% c("preschool", "secondary", "high school", "college")) %>%
  select(-c(health_exp_1m, t2_health_exp_1m)) %>%
  mutate(change_in_expenses = t2_health_exp_3m - health_exp_3m) %>%
  group_by(treatment, education) %>%
  summarize(mean_change_in_expenses = mean(change_in_expenses))

sps_plot <- ggplot(data = sps_subset, mapping = aes(x = education, y = mean_change_in_expenses, fill = treatment)) +
    geom_col()
```

```{r sps8, exercise = TRUE}

```

```{r sps8-hint}
# You can use the position argument in the geom_col() layer
```

### Exercise 9

Because `treatment` column of `sps_subset` is an integer and not a factor, we can't group our data by it. To fix this problem, use `mutate()` and `as.factor()`. 

```{r sps9-setup}
sps_subset <- sps %>%
  filter(education %in% c("preschool", "secondary", "high school", "college")) %>%
  select(-c(health_exp_1m, t2_health_exp_1m)) %>%
  mutate(change_in_expenses = t2_health_exp_3m - health_exp_3m) %>%
  group_by(treatment, education) %>%
  summarize(mean_change_in_expenses = mean(change_in_expenses))
```

```{r sps9, exercise = TRUE}

```

```{r sps9-hint}
# We want to set our new variable to as.factor(treatment)
```

### Exercise 10

Make a new graph `sps_plot_2` and use `fct_reorder()` to reorder the four educations by `mean_change_in_expenses`.

```{r sps10-setup}
sps_subset <- sps %>%
  filter(education %in% c("preschool", "secondary", "high school", "college")) %>%
  select(-c(health_exp_1m, t2_health_exp_1m)) %>%
  mutate(change_in_expenses = t2_health_exp_3m - health_exp_3m) %>%
  group_by(treatment, education) %>%
  summarize(mean_change_in_expenses = mean(change_in_expenses)) %>%
  mutate(treatment = as.factor(treatment))
```

```{r sps10, exercise = TRUE}

```

```{r sps10-hint}
# Look at Question 13 of the Data Wrangling: Kenya section if you are confused 
# about the fct_reorder() function 
```

### Exercise 11

Change the aesthetics of the plot by using `scale_fill_brewer()` with the "Paired" palette. In addition, adjust the `labels` argument of `scale_fill_brewer()` so that the legend's labels are equal to the vector ("No", "Yes").

```{r sps11-setup}
sps_subset <- sps %>%
  filter(education %in% c("preschool", "secondary", "high school", "college")) %>%
  select(-c(health_exp_1m, t2_health_exp_1m)) %>%
  mutate(change_in_expenses = t2_health_exp_3m - health_exp_3m) %>%
  group_by(treatment, education) %>%
  summarize(mean_change_in_expenses = mean(change_in_expenses)) %>%
  mutate(treatment = as.factor(treatment))
sps_plot_2 <- ggplot(data = sps_subset, mapping = aes(x = fct_reorder(education, mean_change_in_expenses), y = mean_change_in_expenses, fill = treatment)) +
    geom_col(position = position_dodge(preserve = "single"))
```

```{r sps11, exercise = TRUE}

```

```{r sps11-hint, eval=FALSE}
sps_plot_2 <- sps_plot_2 + 
    scale_fill_brewer(palette = ..., labels = ...)
```

### Exercise 12

Finally, add `theme_minimal()` to change the style of the graph.

```{r sps12-setup}
sps_subset <- sps %>%
  filter(education %in% c("preschool", "secondary", "high school", "college")) %>%
  select(-c(health_exp_1m, t2_health_exp_1m)) %>%
  mutate(change_in_expenses = t2_health_exp_3m - health_exp_3m) %>%
  group_by(treatment, education) %>%
  summarize(mean_change_in_expenses = mean(change_in_expenses)) %>%
  mutate(treatment = as.factor(treatment))
sps_plot_2 <- ggplot(data = sps_subset, mapping = aes(x = fct_reorder(education, mean_change_in_expenses), y = mean_change_in_expenses, fill = treatment)) +
    geom_col(position = position_dodge(preserve = "single")) + 
  scale_fill_brewer(palette = "Paired", labels = c("No", "Yes"))
```

```{r sps12, exercise = TRUE}

```

### Exercise 13

Great work! The first thing to notice from our graph is that all of the bars are positive, implying that all medical costs (regardless of treatment) went up over time. However, it is also clear that the treatment significantly lowered costs for all education groups. Finally, it is worth noting that the education category `preschool` is the only category that the treatment did not significantly affect. Since the treatment was designed to help less educated people the most, this is definitely a fact worth investigating.

To finish your plot, use `labs()` to change the x-axis label to "education." Also, give the graph a title and subtitle of your choice.

```{r sps13-setup}
sps_subset <- sps %>%
  filter(education %in% c("preschool", "secondary", "high school", "college")) %>%
  select(-c(health_exp_1m, t2_health_exp_1m)) %>%
  mutate(change_in_expenses = t2_health_exp_3m - health_exp_3m) %>%
  group_by(treatment, education) %>%
  summarize(mean_change_in_expenses = mean(change_in_expenses)) %>%
  mutate(treatment = as.factor(treatment))
sps_plot_2 <- ggplot(data = sps_subset, mapping = aes(x = fct_reorder(education, mean_change_in_expenses), y = mean_change_in_expenses, fill = treatment)) +
    geom_col(position = position_dodge(preserve = "single")) + 
  scale_fill_brewer(palette = "Paired", labels = c("No", "Yes")) +
    theme_minimal()
```

```{r sps13, exericse = TRUE}

```

## Shaming 

### Exercise 1

The `shaming` data set chronicles a study that attempted to measure the impact of social pressure on voting. Nearly 350,000 people in Michigan were randomly assigned to 1 of 5 treatment groups before the 2006 Michigan primary. All 5 groups were sent mail before the primary: the "Civic Duty" group had an extra reminder that voting was a civic responsibility, the "Hawthorne" group was told that whether or not they voted would be in the public record, the "Self" group was actually *sent* the public record of whether or not they voted in 2004, and the "Neighbors" group was sent both their voting record and their neighbors' voting record from 2004.

Start by running `skim()` on `shaming`. See if you can find out how many of the participants voted in `general_04`. Also, pay close attention to the data types of each of the variables.

```{r shaming1, exercise = TRUE}

```

### Exercise 2

Make the data set easier to visualize by limiting the columns to `treatment`, `primary_04`, and `primary_06`. Call this new dataset `shaming_subset`.

```{r shaming2, exercise = TRUE}

```

```{r shaming2-hint}
# Use the select() function.
```

### Exercise 3

Use `pivot_longer()` to map the *names* of the `primary_04` and `primary_06` columns to a new column, "year," and the *values* of those two columns to a new column, "voted." What goes wrong?

```{r shaming3-setup}
shaming_subset <- shaming %>%
  select(primary_04, primary_06, treatment)
```

```{r shaming3, exercise = TRUE}

```

```{r shaming3-hint, eval = FALSE}
shaming_subset %>%
  pivot_longer(cols = ..., names_to = ..., values_to = ...)
```

### Exercise 4

`pivot_longer()` won't let us combine one column of `<chr>` data with one column of `<int>` data. Therefore, we're going to have to change the data type of one of the columns.

Before we do that, though, we need to understand the dplyr `if_else()` function. `if_else()` is used alongside `mutate()` to create 2 different values depending on whether a `condition` is `TRUE` or `FALSE`. Run the following code to see how we can categorize the `birth_year` column into 2 groups based on whether the person was born before 1950.

```{r shaming4, exercise = TRUE, exercise.lines = 6}
shaming %>%
  select(birth_year) %>%
  mutate(born_before_1950 = if_else(condition = birth_year < 1950,
                                 true = "yes",
                                 false = "no"))
```

### Exercise 5

Now, use `if_else()` before the `pivot_longer()` statement to `mutate()` the `primary_04` column. The condition should should be a `str_detect()` of the string "Yes" in `primary_04`. If the condition is true, return 1 **as an integer**, and if the condition is false, return 0 **as an integer**.

```{r shaming5-setup}
shaming_subset <- shaming %>%
  select(primary_04, primary_06, treatment) 
```

```{r shaming5, exercise = TRUE, eval = FALSE, exercise.lines = 5}

```

```{r shaming5-hint-1}
# Remember to append the letter "L" to make something an integer; e.g. 22L.
```

```{r shaming5-hint-2}
# The condition of the if_else() should be str_detect(primary_04, "Yes").
```

### Exercise 6

Great job! To continue, group the data by `treatment`, `year`, and `voted`.

```{r shaming6-setup}
shaming_subset <- shaming %>%
  select(primary_04, primary_06, treatment) %>%
  mutate(primary_04 = if_else(condition = str_detect(primary_04, "Yes"),
                              true = 1L,
                              false = 0L)) %>%
  pivot_longer(cols = c(primary_04, primary_06), names_to = "year", values_to = "voted")
```

```{r shaming6, exercise = TRUE}

```

```{r shaming6-hint}
# Use the group_by() function.
```

### Exercise 7

Using `summarize()`, create the variable `num_voters` that simply counts the number of rows in each group.

```{r shaming7-setup}
shaming_subset <- shaming %>%
  select(primary_04, primary_06, treatment) %>%
  mutate(primary_04 = if_else(condition = str_detect(primary_04, "Yes"),
                              true = 1L,
                              false = 0L)) %>%
  pivot_longer(cols = c(primary_04, primary_06), names_to = "year", values_to = "voted") %>%
  group_by(treatment, year, voted)
```

```{r shaming7, exercise = TRUE}

```

```{r shaming7-hint}
# Remember that n() counts the number of rows in each group.
```

### Exercise 8

The `voted` column is a bit difficult to understand, as a numerical value (0 or 1) is used to represent an idea (the person did or did not vote). Use another `if_else()` statement to `mutate()` the `voted` column. Condition your `if_else()` on whether `voted` is equal to 1: true should return "did_vote," and false should return "did_not_vote."

```{r shaming8-setup}
shaming_subset <- shaming %>%
  select(primary_04, primary_06, treatment) %>%
  mutate(primary_04 = if_else(condition = str_detect(primary_04, "Yes"),
                              true = 1L,
                              false = 0L)) %>%
  pivot_longer(cols = c(primary_04, primary_06), names_to = "year", values_to = "voted") %>%
  group_by(treatment, year, voted) %>%
  summarize(num_voters = n())
```

```{r shaming8, exercise = TRUE}

```

```{r shaming8-hint}
# The condition of the if_else() should be voted == 1.
```

### Exercise 9

Now, we want `did_vote` and `did_not_vote` to be their own columns. Call a `pivot_wider()` function that gets its column names from `voted` and its values from `num_voters`.

```{r shaming9-setup}
shaming_subset <- shaming %>%
  select(primary_04, primary_06, treatment) %>%
  mutate(primary_04 = if_else(condition = str_detect(primary_04, "Yes"),
                              true = 1L,
                              false = 0L)) %>%
  pivot_longer(cols = c(primary_04, primary_06), names_to = "year", values_to = "voted") %>%
  group_by(treatment, year, voted) %>%
  summarize(num_voters = n()) %>%
  mutate(voted = if_else(condition = voted == 1,
                         true = "did_vote",
                         false = "did_not_vote"))
```

```{r shaming9, exercise = TRUE}

```

```{r shaming9-hint, eval = FALSE}
shaming_subset <- shaming_subset %>%
  pivot_wider(names_from = ..., values_from = ...)
```

### Exercise 10

`mutate()` a new variable, `pct_voted`, equal to the number of people who `did_vote` divided by the total number of people.

```{r shaming10-setup}
shaming_subset <- shaming %>%
  select(primary_04, primary_06, treatment) %>%
  mutate(primary_04 = if_else(condition = str_detect(primary_04, "Yes"),
                              true = 1L,
                              false = 0L)) %>%
  pivot_longer(cols = c(primary_04, primary_06), names_to = "year", values_to = "voted") %>%
  group_by(treatment, year, voted) %>%
  summarize(num_voters = n()) %>%
  mutate(voted = if_else(condition = voted == 1,
                         true = "did_vote",
                         false = "did_not_vote")) %>%
  pivot_wider(names_from = voted, values_from = num_voters)
```

```{r shaming10, exercise = TRUE}

```

```{r shaming10-hint}
# Note that the total number of people is equal to (did_vote + did_not_vote).
```

### Exercise 11

Call `ggplot()` to make a bar chart that maps `treatment` to the x-axis, `pct_voted` to the y-axis, and `year` to the fill aesthetic. Call this plot `shaming_plot`.

```{r shaming11-setup}
shaming_subset <- shaming %>%
  select(primary_04, primary_06, treatment) %>%
  mutate(primary_04 = if_else(condition = str_detect(primary_04, "Yes"),
                              true = 1L,
                              false = 0L)) %>%
  pivot_longer(cols = c(primary_04, primary_06), names_to = "year", values_to = "voted") %>%
  group_by(treatment, year, voted) %>%
  summarize(num_voters = n()) %>%
  mutate(voted = if_else(condition = voted == 1,
                         true = "did_vote",
                         false = "did_not_vote")) %>%
  pivot_wider(names_from = voted, values_from = num_voters)
```

```{r shaming11, exercise = TRUE, exercise.lines = 14}

```

```{r shaming11-hint}
# Remember to use geom_col() instead of geom_bar() when you map something to the y-axis.
```

### Exercise 12

A stacked barplot is very hard to analyze here. Use the `position_dodge()` function with `preserve` set to "single" to make the graph a dodged barplot.

```{r shaming12-setup}
shaming_subset <- shaming %>%
  select(primary_04, primary_06, treatment) %>%
  mutate(primary_04 = if_else(condition = str_detect(primary_04, "Yes"),
                              true = 1L,
                              false = 0L)) %>%
  pivot_longer(cols = c(primary_04, primary_06), names_to = "year", values_to = "voted") %>%
  group_by(treatment, year, voted) %>%
  summarize(num_voters = n()) %>%
  mutate(voted = if_else(condition = voted == 1,
                         true = "did_vote",
                         false = "did_not_vote")) %>%
  pivot_wider(names_from = voted, values_from = num_voters)

shaming_plot <- ggplot(data = shaming_subset, mapping = aes(x = treatment, y = pct_voted, fill = year)) +
    geom_col()
```

```{r shaming12, exercise = TRUE}

```

```{r shaming12-hint, eval = FALSE}
# Set the position argument of geom_col()
```

### Exercise 13

Use `fct_reorder()` to reorder the five different `treatment`s by `pct_voted`. Call this new plot `shaming_plot_2`.

```{r shaming13-setup}
shaming_subset <- shaming %>%
  select(primary_04, primary_06, treatment) %>%
  mutate(primary_04 = if_else(condition = str_detect(primary_04, "Yes"),
                              true = 1L,
                              false = 0L)) %>%
  pivot_longer(cols = c(primary_04, primary_06), names_to = "year", values_to = "voted") %>%
  group_by(treatment, year, voted) %>%
  summarize(num_voters = n()) %>%
  mutate(voted = if_else(condition = voted == 1,
                         true = "did_vote",
                         false = "did_not_vote")) %>%
  pivot_wider(names_from = voted, values_from = num_voters)
```

```{r shaming13, exercise = TRUE}

```

### Exercise 14

Finally, use the `coord_cartesian` function to adjust the graph's zoom by setting `ylim` to the vector `(0.2, 0.45)`.

```{r shaming14-setup}
shaming_subset <- shaming %>%
  select(primary_04, primary_06, treatment) %>%
  mutate(primary_04 = if_else(condition = str_detect(primary_04, "Yes"),
                              true = 1L,
                              false = 0L)) %>%
  pivot_longer(cols = c(primary_04, primary_06), names_to = "year", values_to = "voted") %>%
  group_by(treatment, year, voted) %>%
  summarize(num_voters = n()) %>%
  mutate(voted = if_else(condition = voted == 1,
                         true = "did_vote",
                         false = "did_not_vote")) %>%
  pivot_wider(names_from = voted, values_from = num_voters)

shaming_plot_2 <- ggplot(data = shaming_subset, mapping = aes(x = fct_reorder(treatment, pct_voted), y = pct_voted, fill = year)) +
    geom_col(position = position_dodge(preserve = "single"))
```

```{r shaming14, exercise = TRUE}

```

### Exercise 15

From this graph, the first thing to notice is that all five of the treatment categories had approximately the same average voter turnout in 2004. We can also see that turnout decreased across the board in 2006. However, each additional level of social shaming led to a substantial increase in voter turnout, with the "Neighbors" treatment particularly effective.

To finish your plot, use `labs()` to change the x-axis label to "treatment." In addition, give the graph a title and subtitle of your choice.

```{r shaming15-setup}
shaming_subset <- shaming %>%
  select(primary_04, primary_06, treatment) %>%
  mutate(primary_04 = if_else(condition = str_detect(primary_04, "Yes"),
                              true = 1L,
                              false = 0L)) %>%
  pivot_longer(cols = c(primary_04, primary_06), names_to = "year", values_to = "voted") %>%
  group_by(treatment, year, voted) %>%
  summarize(num_voters = n()) %>%
  mutate(voted = if_else(condition = voted == 1,
                         true = "did_vote",
                         false = "did_not_vote")) %>%
  pivot_wider(names_from = voted, values_from = num_voters)

shaming_plot_2 <- ggplot(data = shaming_subset, 
                         mapping = aes(x = fct_reorder(treatment, pct_voted), y = pct_voted, fill = year)) +
    geom_col(position = position_dodge(preserve = "single")) +
    coord_cartesian(ylim = c(0.2, 0.45))
```

```{r shaming15, exercise = TRUE}

```

## Q-Guide
### Exercise 1 

The `qscores` data set includes information about 748 courses at Harvard during the 2018-2019 school year, including their department, student enrollment, average time spent on homework, and the average student rating of the course.

Start by piping `qscores` into `sample_n()` to view 5 random rows in the data set.

```{r qscores1, exercise = TRUE}

```

### Exercise 2

Our goal will be to analyze the homework patterns of Harvard classes by department. To start, use a pipe to `select()` the `department` and `hours` columns (`hours` represents the average workload of a class per week in hours, based on student surveys). Call this new dataset `q_subset`. 

```{r qscores2, exercise = TRUE}

```

### Exercise 3

Next, group the data by `department`.
```{r qscores3-setup}
q_subset <- qscores %>%
  select(department, hours)
```

```{r qscores3, exercise = TRUE}

```

```{r qscores3-hint}
# Use the group_by() function.
```

### Exercise 4

Use `summarize()` to create 3 new variables: `num_classes` equal to the number of rows (i.e. classes) in each `department` group, `mean_hours` equal to the average value of `hours` by group, and `sd_hours` equal to the standard deviation (`sd()`) of `hours` by group.

```{r qscores4-setup}
q_subset <- qscores %>%
  select(department, hours) %>%
  group_by(department)
```

```{r qscores4, exercise = TRUE, exercise.lines = 4}

```

```{r qscores4-hint-1}
# The n() function returns the number of rows in each group.
```

```{r qscores4-hint-2, eval = FALSE}
q_subset <- q_subset %>%
  summarize(num_classes = ..., mean_hours = ..., sd_hours = ...)
```

### Exercise 5

`arrange()` the data set by `num_classes` in `desc()`ending order.

```{r qscores5-setup}
q_subset <- qscores %>%
  select(department, hours) %>%
  group_by(department) %>%
  summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours))
```

```{r qscores5, exercise = TRUE}

```

### Exercise 6

Use `slice()` to return the top 3 rows of the data set, i.e. the 3 largest departments at Harvard by number of classes.

```{r qscores6-setup}
q_subset <- qscores %>%
  select(department, hours) %>%
  group_by(department) %>%
  summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>%
  arrange(desc(num_classes))
```

```{r qscores6, exercise = TRUE}

```

```{r qscores6-hint}
# Remember that a:b returns all of the numbers from a to b. For example, 1:10 returns every number between 1 and 10.
```

### Exercise 7

Group the data by `department` one more time (the data is no longer grouped since we removed some `department`s with our `slice()` statement).

```{r qscores7-setup}
q_subset <- qscores %>%
  select(department, hours) %>%
  group_by(department) %>%
  summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>%
  arrange(desc(num_classes)) %>%
  slice(1:3)
```

```{r qscores7, exercise = TRUE}

```

### Exercise 8

Using `summarize()`, create a new variable, `rnorm_values`. `rnorm_values` should be equal to the result of an `rnorm()` statement. The `rnorm()` statement should have `n` equal to `num_classes`, `mean` equal to `mean_hours`, and `sd` equal to `sd_hours` (in other words, we are generating `n` completely random numbers, but the numbers should have the same mean and standard deviation as the actual Harvard classes do).

```{r qscores8-setup}
q_subset <- qscores %>%
  select(department, hours) %>%
  group_by(department) %>%
  summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>%
  arrange(desc(num_classes)) %>%
  slice(1:3) %>%
  group_by(department)
```

```{r qscores8, exercise = TRUE}

```

```{r qscores8-hint, eval=FALSE}
qsubset <- q_subset %>%
  summarize(rnorm_values = rnorm(...))
```

### Exercise 9

Great work! Our next goal will be to create a new column with the homework values of the *actual* Harvard classes. To do so, start a new pipe at the very beginning of your code. Use the pipe to `filter()` qscores to the "ECON," "MATH," and "GOV" departments (which we have already discovered are the 3 largest departments in our data set). Call this `q_subset_2`. 

```{r qscores9, exercise = TRUE}

```

```{r qscores9-hint}
# Remember to use the %in% operator.
```

### Exercise 10

`arrange()` both `q_subset` and `q_subset_2` by `department`. (because `department` is a character variable, this will arrange them in alphabetical order).

```{r qscores10-setup}
q_subset_2 <- qscores %>%
  filter(department %in% c("ECON", "MATH", "GOV"))
```

```{r qscores10, exercise = TRUE}

```

### Exercise 11

`select()` only the `hours` variable from `q_subset_2`.
```{r qscores11-setup}
q_subset_2 <- qscores %>%
  filter(department %in% c("ECON", "MATH", "GOV")) %>%
  arrange(department)

q_subset <- qscores %>%
  select(department, hours) %>%
  group_by(department) %>%
  summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>%
  arrange(desc(num_classes)) %>%
  slice(1:3) %>%
  group_by(department) %>%
  summarize(rnorm_values = rnorm(n = num_classes, mean = mean_hours, sd = sd_hours)) %>%
  arrange(department)

```

```{r qscores11, exercise = TRUE}

```

### Exercise 12 

Finally, use `bind_cols()` to bind the columns in `q_subset_2` to the columns in `q_subset`.
Call this `q_bind`.

Notice how careful we were to `arrange()` both pipes by the same variable before we conducted our column bind. This is really important because the rows **must** be in the same order before you column bind. Otherwise, values will be bound to the wrong rows (for example, some `hours` from ECON classes might end up paired with some `rnorm_values` from MATH classes, which we certainly don't want).

```{r qscores12-setup}
q_subset_2 <- qscores %>%
  filter(department %in% c("ECON", "MATH", "GOV")) %>%
  arrange(department) %>%
  select(hours)

q_subset <- qscores %>%
  select(department, hours) %>%
  group_by(department) %>%
  summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>%
  arrange(desc(num_classes)) %>%
  slice(1:3) %>%
  group_by(department) %>%
  summarize(rnorm_values = rnorm(n = num_classes, mean = mean_hours, sd = sd_hours)) %>%
  arrange(department)
```

```{r qscores12, exercise = TRUE}

```

### Exercise 13

Before we make our `ggplot()`, use `pivot_longer()` to transform the `rnorm_values` and `hours` columns into two new columns: "type," equal to either `rnorm_values` or `hours`, and "value," equal to the value currently contained in one of those two columns.

```{r qscores13-setup}
q_subset_2 <- qscores %>%
  filter(department %in% c("ECON", "MATH", "GOV")) %>%
  arrange(department) %>%
  select(hours)

q_subset <- qscores %>%
  select(department, hours) %>%
  group_by(department) %>%
  summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>%
  arrange(desc(num_classes)) %>%
  slice(1:3) %>%
  group_by(department) %>%
  summarize(rnorm_values = rnorm(n = num_classes, mean = mean_hours, sd = sd_hours)) %>%
  arrange(department)

q_bind <- bind_cols(q_subset, q_subset_2)
```

```{r qscores13, exercise = TRUE}

```

```{r qscores13-hint, eval = FALSE}

```

### Exercise 14

Use `ggplot()` to make a histogram that maps `value` to the x-axis. Give the histogram a `binwidth` of 2. Call this histogram `q_plot`. 
```{r qscores14-setup}
q_subset_2 <- qscores %>%
  filter(department %in% c("ECON", "MATH", "GOV")) %>%
  arrange(department) %>%
  select(hours)

q_subset <- qscores %>%
  select(department, hours) %>%
  group_by(department) %>%
  summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>%
  arrange(desc(num_classes)) %>%
  slice(1:3) %>%
  group_by(department) %>%
  summarize(rnorm_values = rnorm(n = num_classes, mean = mean_hours, sd = sd_hours)) %>%
  arrange(department)

q_bind <- bind_cols(q_subset, q_subset_2) %>%
  pivot_longer(cols = c(rnorm_values, hours), names_to = "type", values_to = "value")
```

```{r qscores14, exercise = TRUE}

```

### Exercise 15

Use `facet_grid()` to facet our histogram into rows by `type` and columns by `department`.
```{r qscores15-setup}
q_subset_2 <- qscores %>%
  filter(department %in% c("ECON", "MATH", "GOV")) %>%
  arrange(department) %>%
  select(hours)

q_subset <- qscores %>%
  select(department, hours) %>%
  group_by(department) %>%
  summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>%
  arrange(desc(num_classes)) %>%
  slice(1:3) %>%
  group_by(department) %>%
  summarize(rnorm_values = rnorm(n = num_classes, mean = mean_hours, sd = sd_hours)) %>%
  arrange(department)

q_bind <- bind_cols(q_subset, q_subset_2) %>%
  pivot_longer(cols = c(rnorm_values, hours), names_to = "type", values_to = "value")

q_plot <- ggplot(data = q_bind, mapping = aes(x = value)) +
    geom_histogram(binwidth = 2)
```

```{r qscores15, exercise = TRUE, exercise.lines = 19}

```

```{r qscores15-hint}
# Remember that when using facet_grid(), the variable to the left of the "~" is the variable that will be used to facet the graph into rows.
```

### Exercise 16

Awesome work! This graph gives the actual homework times for Harvard classes on the top row and an imitation on the bottom row by utilizing a normal distribution. The first thing to notice is that the MATH department has a significantly higher mean homework amount than the ECON and GOV departments (this is most easily seen on the bottom row of graphs). Furthermore, the graphs on the top tend to skew left compared to the normal distributions on the bottom, implying that professors are less willing to give substantially more homework than the typical class in that department.

To finish your plot, use `labs()` to give the graph a title and subtitle of your choice.

```{r qscores16-setup}
q_subset_2 <- qscores %>%
  filter(department %in% c("ECON", "MATH", "GOV")) %>%
  arrange(department) %>%
  select(hours)

q_subset <- qscores %>%
  select(department, hours) %>%
  group_by(department) %>%
  summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>%
  arrange(desc(num_classes)) %>%
  slice(1:3) %>%
  group_by(department) %>%
  summarize(rnorm_values = rnorm(n = num_classes, mean = mean_hours, sd = sd_hours)) %>%
  arrange(department)

q_bind <- bind_cols(q_subset, q_subset_2) %>%
  pivot_longer(cols = c(rnorm_values, hours), names_to = "type", values_to = "value")

q_plot <- ggplot(data = q_bind, mapping = aes(x = value)) +
    geom_histogram(binwidth = 2) +
     facet_grid(type ~ department)
```

```{r qscores16, exercise = TRUE, exercise.lines = 20}

```

```{r qscores16-hint, eval = FALSE}

```


<!-- DK: Commented out this whole thing. Need to be more careful. Key issue seems to be that there is an object --- most_common_races --- which we need to create because it is used later in a join. But nowhere is it created, so the join fails. Please fix this. -->

<!-- ## CCES Dataset -->
<!-- ### Exercise 1 -->

<!-- The `cces` data set, an acronym for "Cooperative Congressional Election Study," includes the presidential approval (and a bunch of demographic data) from over 450,000 individual Americans. -->

<!-- Since this data set is so large, start by using `sample_n()` to return 10 random observations from `cces`. -->

<!-- ```{r cces1, exercise = TRUE} -->

<!-- ``` -->

<!-- ### Exercise 2 -->

<!-- Use `select()` and the `c()` function to remove the `news`, `econ`, `marstat`, and `approval_ch` variables. Call this new dataset `cces_subset`.  -->

<!-- ```{r cces2, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r cces2-hint-1} -->
<!-- # Remember that select(-column_name) returns all of the columns in the data set except for that column. -->
<!-- ``` -->

<!-- ```{r cces2-hint-2, eval = FALSE} -->
<!-- cces %>% -->
<!--   select(-c(...)) -->
<!-- ``` -->

<!-- ### Exercise 3 -->

<!-- Use `filter()` to limit the data to the years 2009-2016 (to keep the approval data limited to a single president, Obama). Try to use the `%in%` operator to keep your code concise and clear. Don't forget to reassign this as `cces_subset`. -->

<!-- ```{r cces3-setup} -->
<!-- cces_subset <- cces %>% -->
<!--   select(-c(news, econ, marstat, approval_ch)) -->
<!-- ``` -->

<!-- ```{r cces3, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r cces3-hint} -->
<!-- # Remember that c(a:b) makes a vector from a to b. For example, c(1:10) makes a vector with the numbers from 1 to 10. -->
<!-- ``` -->

<!-- ### Exercise 4 -->

<!-- Call `filter` a second time and  remove any observations with an `ideology` of "Not Sure" (this makes the trends in our data easier to detect). -->

<!-- ```{r cces4-setup} -->
<!-- cces_subset <- cces %>% -->
<!--   select(-c(news, econ, marstat, approval_ch)) %>% -->
<!--   filter(year %in% c(2009:2016)) -->
<!-- ``` -->

<!-- ```{r cces4, exercise = TRUE, exercise.lines = 4} -->

<!-- ``` -->

<!-- ### Exercise 5 -->

<!-- Now that `cces` is organized, our goal will be to plot the relationship between `race`, `ideology`, and `approval` of President Obama. Start by grouping the data by `race` and `ideology`. -->
<!-- ```{r cces5-setup} -->
<!-- cces_subset <- cces %>% -->
<!--   select(-c(news, econ, marstat, approval_ch)) %>% -->
<!--   filter(year %in% c(2009:2016), ideology != "Not Sure") -->
<!-- ``` -->

<!-- ```{r cces5, exercise = TRUE, exercise.lines = 4} -->

<!-- ``` -->

<!-- ### Exercise 6 -->

<!-- Use `summarize` to return a tibble with a new variable, `mean_approval`, that is equal to the average `approval` for each group. What goes wrong? -->

<!-- ```{r cces6-setup} -->
<!-- cces_subset <- cces %>% -->
<!--   select(-c(news, econ, marstat, approval_ch)) %>% -->
<!--   filter(year %in% c(2009:2016), ideology != "Not Sure") %>% -->
<!--   group_by(race, ideology) -->
<!-- ``` -->

<!-- ```{r cces6, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r cces6-hint, eval = FALSE} -->
<!-- # Don't forget to use the mean() function within summarize() -->
<!-- ``` -->

<!-- ### Exercise 7 -->

<!-- Almost all of our rows have an `NA` for `mean_approval`! This is because if any single row has an `NA` in our original table, the `mean()` function will return `NA`. To avoid this, take take the `mean()` again and set the `na.rm` argument to TRUE. -->

<!-- ```{r cces7-setup} -->
<!-- cces_subset <- cces %>% -->
<!--   select(-c(news, econ, marstat, approval_ch)) %>% -->
<!--   filter(year %in% c(2009:2016), ideology != "Not Sure") %>% -->
<!--   group_by(race, ideology) -->
<!-- ``` -->

<!-- ```{r cces7, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r cces7-hint, eval=FALSE} -->
<!-- cces_subset <- cces_subset %>% -->
<!--   summarize(mean_approval = mean(approval, ...)) -->
<!-- ``` -->

<!-- ### Exercise 8 -->

<!-- Use `ggplot()` to ake a bar chart with `ideology` on the x-axis, `mean_approval` on the y-axis, and `race` as the fill aesthetic. Call this plot `cces_plot`.  -->

<!-- ```{r cces8-setup} -->
<!-- cces_subset <- cces %>% -->
<!--   select(-c(news, econ, marstat, approval_ch)) %>% -->
<!--   filter(year %in% c(2009:2016), ideology != "Not Sure") %>% -->
<!--   group_by(race, ideology) %>% -->
<!--   summarize(mean_approval = mean(approval, na.rm = TRUE)) -->
<!-- ``` -->

<!-- ```{r cces8} -->

<!-- ``` -->

<!-- ```{r cces8-hint} -->
<!-- # Remember to use geom_col() instead of geom_bar() when you map a variable to the y-axis. -->
<!-- ``` -->

<!-- ### Exercise 9 -->

<!-- This stacked bar chart is a good start, but it's still pretty difficult to understand. Use the `position_dodge` function with `preserve` equal to "single" to make the graph clearer. We've taken the liberty of removing the `geom_col()` in the previous question, so you can start fresh. -->

<!-- ```{r cces9-setup} -->
<!-- cces_subset <-  cces %>% -->
<!--   select(-c(news, econ, marstat, approval_ch)) %>% -->
<!--   filter(year %in% c(2009:2016), ideology != "Not Sure") %>% -->
<!--   group_by(race, ideology) %>% -->
<!--   summarize(mean_approval = mean(approval, na.rm = TRUE)) -->
<!-- cces_plot  <- ggplot(data = cces_subset, mapping = aes(x = ideology, y = mean_approval, fill = race))  -->
<!-- ``` -->

<!-- ```{r cces9, exercise = TRUE, exercise.lines = 8} -->

<!-- ``` -->

<!-- ```{r cces9-hint, eval = FALSE} -->
<!-- cces_plot <- cces_plot +  -->
<!--   geom_col(position = ...) -->
<!-- ``` -->

<!-- ### Exercise 10 -->

<!-- Bar charts are easier to read if they are increasing from left to right. Use a `fct_` function to reorder the chart based on each `ideology`'s `mean_approval`. Call this new plot `cces_plot_2`.  -->

<!-- <!-- Comment: technically there are separate mean_approval values for each race; is there any way to get around this (i.e. only sort by the values for one race?) Or would this just sort by the average of mean_approval? --> -->
<!-- ```{r cces10-setup} -->
<!-- cces_subset <-  cces %>% -->
<!--   select(-c(news, econ, marstat, approval_ch)) %>% -->
<!--   filter(year %in% c(2009:2016), ideology != "Not Sure") %>% -->
<!--   group_by(race, ideology) %>% -->
<!--   summarize(mean_approval = mean(approval, na.rm = TRUE)) -->

<!-- ``` -->

<!-- ```{r cces10, exercise = TRUE, exercise.lines = 8} -->

<!-- ``` -->

<!-- ```{r cces10-hint} -->
<!-- # Try using fct_reorder(). -->
<!-- ``` -->

<!-- ### Exercise 11 -->

<!-- Our graph is looking good, but the 8 separate races take up a lot of space and make it hard to read. Let's try to limit the graph to the 3 most common races in our data set. Start by making a new pipe that groups `cces` by `race`. Call this `cces_subset_2`. -->

<!-- ```{r cces11, exercise = TRUE, exercise.lines = 10, eval = FALSE} -->

<!-- ``` -->

<!-- ### Exercise 12 -->

<!-- Next, use `summarize()` on the to create a new variable in `cces_subset_2`, `num_ppl`, equal to the number of times each race occurs. -->
<!-- ```{r cces12-setup} -->
<!-- cces_subset_2 <- cces %>% -->
<!--   group_by(race) -->
<!-- ``` -->

<!-- ```{r cces12, exercise = TRUE, exercise.lines = 11} -->

<!-- ``` -->

<!-- ```{r cces12-hint} -->
<!-- # Remember that the function n() counts the number of rows in each group. -->
<!-- ``` -->

<!-- ### Exercise 13 -->

<!-- `arrange()` `cces_subset_2` by `num_ppl` in descending order. -->

<!-- ```{r cces13-setup} -->
<!-- cces_subset_2 <- cces %>% -->
<!--   group_by(race) %>% -->
<!--   summarize(num_ppl = n()) -->
<!-- ``` -->

<!-- ```{r cces13, exercise = TRUE, exercise.lines = 12} -->

<!-- ``` -->

<!-- ```{r cces13-hint} -->
<!-- # Remember to incorporate desc() into your arrange() function. -->
<!-- ``` -->

<!-- ### Exercise 14 -->

<!-- Finally, use `slice()` to keep the top 3 rows of `cces_subset_2`.. -->
<!-- ```{r cces14-setup} -->
<!-- cces_subset_2 <- cces %>% -->
<!--   group_by(race) %>% -->
<!--   summarize(num_ppl = n()) %>% -->
<!--   arrange(desc(num_ppl)) -->
<!-- ``` -->

<!-- ```{r cces14, exercise = TRUE} -->

<!-- ``` -->

<!-- ### Exercise 15 -->

<!-- Returning to `cces_subset`, use a filtering join before our `ggplot()` call so that only the races in `cces_subset_2` remain. -->
<!-- ```{r cces15-setup} -->
<!-- cces_subset_2 <- cces %>% -->
<!--   group_by(race) %>% -->
<!--   summarize(num_ppl = n()) %>% -->
<!--   arrange(desc(num_ppl)) %>% -->
<!--   slice(1:3) -->

<!-- cces_subset <- cces %>% -->
<!--   select(-c(news, econ, marstat, approval_ch)) %>% -->
<!--   filter(year %in% c(2009:2016), ideology != "Not Sure") %>% -->
<!--   group_by(race, ideology) %>% -->
<!--   summarize(mean_approval = mean(approval, na.rm = TRUE)) -->
<!-- ``` -->

<!-- ```{r cces15, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r cces15-hint-1} -->
<!-- # Did you remember to use semi_join()? -->
<!-- ``` -->

<!-- ```{r cces15-hint-2, eval=FALSE} -->
<!-- cces_subset <- cces_subset %>% -->
<!--   semi_join(..., by = ...) -->
<!-- ``` -->

<!-- ### Exercise 16 -->

<!-- Our graph is starting to look good! Now, create the same plot you had previously using the new data. Call this `cces_plot_2`. To improve the aesthetics, add a `scale_` function to use RColorBrewer's "Dark2" palette to fill the bars. -->

<!-- ```{r cces16-setup} -->
<!-- cces_subset_2 <- cces %>% -->
<!--   group_by(race) %>% -->
<!--   summarize(num_ppl = n()) %>% -->
<!--   arrange(desc(num_ppl)) %>% -->
<!--   slice(1:3) -->

<!-- cces_subset <- cces %>% -->
<!--   select(-c(news, econ, marstat, approval_ch)) %>% -->
<!--   filter(year %in% c(2009:2016), ideology != "Not Sure") %>% -->
<!--   group_by(race, ideology) %>% -->
<!--   summarize(mean_approval = mean(approval, na.rm = TRUE)) %>% -->
<!--   semi_join(most_common_races, by = "race") -->
<!-- ``` -->

<!-- ```{r cces16, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r cces16-hint-1} -->
<!-- # Remember that because we want to change the fill aesthetic (and not the color aesthetic), we have to adjust the syntax of our scale_ function -->
<!-- ``` -->

<!-- ```{r cces16-hint-2, eval = FALSE} -->
<!-- cces_plot_2 <- cces_plot_2 %>% + -->
<!--     scale_fill_brewer(...) -->
<!-- ``` -->

<!-- ### Exercise 17 -->

<!-- We can now clearly see the trend that more liberal Americans had a higher approval of President Obama. In addition, Black Americans gave Obama higher approval than Hispanic Americans, who, in turn, gave Obama higher approval than white Americans. -->

<!-- To finish your plot, use `labs()` to change the x-axis label so it simply reads as "ideology." In addition, give the graph a title and subtitle of your choosing.  -->
<!-- ```{r cces17-setup} -->
<!-- cces_subset_2 <- cces %>% -->
<!--   group_by(race) %>% -->
<!--   summarize(num_ppl = n()) %>% -->
<!--   arrange(desc(num_ppl)) %>% -->
<!--   slice(1:3) -->

<!-- cces_subset <- cces %>% -->
<!--   select(-c(news, econ, marstat, approval_ch)) %>% -->
<!--   filter(year %in% c(2009:2016), ideology != "Not Sure") %>% -->
<!--   group_by(race, ideology) %>% -->
<!--   summarize(mean_approval = mean(approval, na.rm = TRUE)) %>% -->
<!--   semi_join(most_common_races, by = "race") -->

<!-- cces_plot_2 <- ggplot(data = cces_subset, mapping = aes(x = fct_reorder(ideology, mean_approval), y = mean_approval, fill = race)) + -->
<!--     geom_col(position = position_dodge(preserve = "single")) + -->
<!--     scale_fill_brewer(palette = "Dark2") -->
<!-- ``` -->

<!-- ```{r cces17, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r cces17-hint, eval = FALSE} -->
<!-- cces_plot_2 + -->
<!--     labs(...) -->
<!-- ``` -->

## National Election
### Exercise 1

`nes`, short for "National Election Studies," contains the personal and political information of almost 40,000 American voters, as well as whether or not they voted in that year's presidential election.

Start by running `skim()` on `nes`. See if you can figure out the first and last years in the data set.

```{r nes1, exercise = TRUE}

```

### Exercise 2

Use `levels()` and the `$` operator to return the levels of the `education` variable. What are they?

```{r nes2, exercise = TRUE}

```

```{r nes2-hint}
# The factor that we'd like to investigate is nes$education.
```

### Exercise 3

Select the `year`, `education`, `pres_appr`, and `voted` columns in `nes`. Call this `nes_subset`. 

```{r nes3, exercise = TRUE}
nes
```

### Exercise 4

Continue by filtering the tibble such that `education` is either "Some Highschool," "Highschool," "Some College," or "Adv. Degree."
```{r nes4-setup}
nes_subset <- nes %>%
  select(c(year, education, pres_appr, voted))
```

```{r nes4, exercise = TRUE}

```

```{r nes4-hint}
# Remember to use the %in% operator alongside the c() function.
```

### Exercise 5

After filtering a factor, always remember that the *levels* of the factor have not been removed. To fix this, add a call to the pipe that drops (i.e. permanently removes) all deleted levels.

```{r nes5-setup}
nes_subset <- nes %>%
  select(c(year, education, pres_appr, voted)) %>%
  filter(education %in% c("Some Highschool", "Highschool", "Some College", "Adv. Degree"))
```

```{r nes5, exercise = TRUE}

```

```{r nes5-hint}
# Use the droplevels() function.
```

### Exercise 6

<!-- DK: This example does not flow very well with the one above. The above does not keep ideology around, but, in this example, we need it. -->

The dplyr `if_else()` function can be used alongside `mutate()` and `as.factor()` to create a factor with two levels depending on whether a certain `condition` is met. Run the code below to see how we can use `if_else()` to separate the `nes` data set into 2 groups based on whether the value of `ideology` is positive.

```{r nes6, exercise = TRUE}
nes_subset <- nes %>%
  select(c(year, education, pres_appr, voted, ideology)) %>%
  filter(education %in% c("Some Highschool", "Highschool", "Some College", "Adv. Degree")) %>% 
  mutate(pos_ideology = as.factor(if_else(condition = ideology > 0,
                                          true = "ideology_is_positive",
                                          false = "ideology_not_positive")))
```

### Exercise 7

Now, use `if_else()` to `mutate()` a new variable, `opinion`. `opinion` should be a **factor** that equals "has_opinion" if that person either approves *or* disapproves of the president, but "no_opinion" otherwise. To do this, use the `if_else()` function with the condition being detection of the pattern "prove" in the string `pres_appr`.
```{r nes7-setup}
nes_subset <- nes %>%
  select(c(year, education, pres_appr, voted)) %>%
  filter(education %in% c("Some Highschool", "Highschool", "Some College", "Adv. Degree")) %>%
  droplevels()
```

```{r nes7, exercise = TRUE, exercise.lines = 5}

```

```{r nes7-hint-1}
# Remember to use as.factor() before if_else().
```

```{r nes7-hint-2}
# The function we want to use for the condition is str_detect().
```

```{r nes7-hint-3, eval = FALSE}
nes_subset <- nes_subset %>%
  mutate(opinion = as.factor(if_else(condition = str_detect(...),
                                     true = ...,
                                     false = ...)))
```

### Exercise 8

Our goal for the next few exercises will be to calculate voter turnout based on their education and whether or not they have an opinion of the president. 

To start, group the tibble by `year`, `voted`, `opinion`, and `education`. Then, use `summarize()` to make a new variable, `count`, that simply counts the number of people (i.e. rows) in each group. What goes wrong?

```{r nes8-setup}
nes_subset <- nes %>%
  select(c(year, education, pres_appr, voted)) %>%
  filter(education %in% c("Some Highschool", "Highschool", "Some College", "Adv. Degree")) %>%
  droplevels() %>%
  mutate(opinion = as.factor(if_else(condition = str_detect(pres_appr, "prove"),
                                     true = "has_opinion",
                                     false = "no_opinion")))
```

```{r nes8, exercise = TRUE}

```

```{r nes8-hint}
# Remember that the n() function counts the number of rows in each group.
```

### Exercise 9

If we look closely, many of our rows have a value of `NA` for either `voted` or `opinion`! Furthermore, `n()` doesn't have an `na.rm` argument. To remove the `NA`s, use tidyr's `drop_na()` and then, call `group_by()` and `summarize()` again. 
```{r nes9-setup}
nes_subset <- nes %>%
  select(c(year, education, pres_appr, voted)) %>%
  filter(education %in% c("Some Highschool", "Highschool", "Some College", "Adv. Degree")) %>%
  droplevels() %>%
  mutate(opinion = as.factor(if_else(condition = str_detect(pres_appr, "prove"),
                                     true = "has_opinion",
                                     false = "no_opinion")))
```

```{r nes9, exercise = TRUE}

```

```{r nes9-hint, eval = FALSE}
nes_subset <- nes_subset %>% 
  drop_na(...) %>%
  group_by(...) %>%
  summarize(...)
```

### Exercise 10

Our goal is to calculate voter turnout, the number of people who voted divided by the total number of people. Therefore, we want `Yes` and `No` (currently in the `voted` column) to be their own columns with the values that are currently in the `count` column.

Use one of the `pivot_` functions to tidy our data in this way.

```{r nes10-setup}
nes_subset <- nes %>%
  select(c(year, education, pres_appr, voted)) %>%
  filter(education %in% c("Some Highschool", "Highschool", "Some College", "Adv. Degree")) %>%
  droplevels() %>%
  mutate(opinion = as.factor(if_else(condition = str_detect(pres_appr, "prove"),
                                     true = "has_opinion",
                                     false = "no_opinion"))) %>%
  drop_na(education, opinion) %>%
  group_by(year, voted, opinion, education) %>%
  summarize(count = n())
```

```{r nes10, exercise = TRUE}

```

```{r nes10-hint-1}
# Because we're making new columns from values, we want the pivot_wider() function.
```

```{r nes10-hint-2, eval = FALSE}
nes_subset <- nes_subset %>%
  pivot_wider(names_from = ..., values_from = ...)
```

### Exercise 11

Great job! Now, to calculate turnout, simply `mutate()` another variable, `turnout`, equal to the number of people who voted (the number of `Yes`) divided by the total number of people.
```{r nes11-setup}
nes_subset <- nes %>%
  select(c(year, education, pres_appr, voted)) %>%
  filter(education %in% c("Some Highschool", "Highschool", "Some College", "Adv. Degree")) %>%
  droplevels() %>%
  mutate(opinion = as.factor(if_else(condition = str_detect(pres_appr, "prove"),
                                     true = "has_opinion",
                                     false = "no_opinion"))) %>%
  drop_na(education, opinion) %>%
  group_by(year, voted, opinion, education) %>%
  summarize(count = n()) %>%
  pivot_wider(names_from = voted, values_from = count)
```

```{r nes11, exercise = TRUE}

```

```{r nes11-hint}
# Remember that the total number of people in each group is (Yes + No).
```

### Exercise 12

Next, use `ggplot()` named `nes_plot` to make a line graph that maps `year` to the x-axis, `turnout` to the y-axis, and `education` to both the color and linetype aesthetics.

```{r nes12-setup}
nes_subset <- nes %>%
  select(c(year, education, pres_appr, voted)) %>%
  filter(education %in% c("Some Highschool", "Highschool", "Some College", "Adv. Degree")) %>%
  droplevels() %>%
  mutate(opinion = as.factor(if_else(condition = str_detect(pres_appr, "prove"),
                                     true = "has_opinion",
                                     false = "no_opinion"))) %>%
  drop_na(education, opinion) %>%
  group_by(year, voted, opinion, education) %>%
  summarize(count = n()) %>%
  pivot_wider(names_from = voted, values_from = count) %>%
  mutate(turnout = Yes / (Yes + No))
```

```{r nes12, exercise = TRUE}

```

### Exercise 13

Use `facet_wrap` to facet the graph by opinion.

```{r nes13-setup}
nes_subset <- nes %>%
  select(c(year, education, pres_appr, voted)) %>%
  filter(education %in% c("Some Highschool", "Highschool", "Some College", "Adv. Degree")) %>%
  droplevels() %>%
  mutate(opinion = as.factor(if_else(condition = str_detect(pres_appr, "prove"),
                                     true = "has_opinion",
                                     false = "no_opinion"))) %>%
  drop_na(education, opinion) %>%
  group_by(year, voted, opinion, education) %>%
  summarize(count = n()) %>%
  pivot_wider(names_from = voted, values_from = count) %>%
  mutate(turnout = Yes / (Yes + No))

nes_plot <- ggplot(data = nes_subset, 
                   mapping = aes(x = year, y = turnout, 
                                 color = education, linetype = education)) +
    geom_line()
```

```{r nes13, exercise = TRUE}

```

```{r nes13-hint, eval = FALSE}
nes_plot <- nes_plot + 
    facet_wrap(...)
```

### Exercise 14

This graph is starting to look pretty good, but the ordering of the legend is a bit confusing. Try using an `fct_` function to reorder the legend (both the color *and* linetype aesthetics) so that Adv. Degree is first, Some College is second, and so on. What goes wrong? Call this plot `nes_plot_2`. 

```{r nes14-setup}
nes_subset <- nes %>%
  select(c(year, education, pres_appr, voted)) %>%
  filter(education %in% c("Some Highschool", "Highschool", "Some College", "Adv. Degree")) %>%
  droplevels() %>%
  mutate(opinion = as.factor(if_else(condition = str_detect(pres_appr, "prove"),
                                     true = "has_opinion",
                                     false = "no_opinion"))) %>%
  drop_na(education, opinion) %>%
  group_by(year, voted, opinion, education) %>%
  summarize(count = n()) %>%
  pivot_wider(names_from = voted, values_from = count) %>%
  mutate(turnout = Yes / (Yes + No))
```

```{r nes14, exercise = TRUE}

```

```{r nes14-hint-1}
# Because this is a line graph, we want to use fct_reorder2().
```


### Exercise 15

Although 3 of the 4 `education` statuses are reordered successfully, Adv. Degree is left on the bottom because it doesn't appear in the second graph. To fix this problem, change the `.fun` argument of both `fct_reorder2()` calls to first2 (the default is last2). Call this plot `nes_plot_3`. 

```{r nes15-setup}
nes_subset <- nes %>%
  select(c(year, education, pres_appr, voted)) %>%
  filter(education %in% c("Some Highschool", "Highschool", "Some College", "Adv. Degree")) %>%
  droplevels() %>%
  mutate(opinion = as.factor(if_else(condition = str_detect(pres_appr, "prove"),
                                     true = "has_opinion",
                                     false = "no_opinion"))) %>%
  drop_na(education, opinion) %>%
  group_by(year, voted, opinion, education) %>%
  summarize(count = n()) %>%
  pivot_wider(names_from = voted, values_from = count) %>%
  mutate(turnout = Yes / (Yes + No))
```

```{r nes15, exercise = TRUE}

```

```{r nes15-hint, eval = FALSE}
nes_plot_3 <- ggplot(data = nes_subset, 
                     mapping = aes(x = year, y = turnout, 
                                   color = fct_reorder2(education, year, turnout, 
                                                        .fun = ...), 
                                   linetype = fct_reorder2(education, year, 
                                                           turnout, .fun = ...))) +
    geom_line() +
    facet_wrap(~ opinion)
```

### Exercise 16

<!-- DK: Is this stuff really working? Why don't we need to pass data to create nes_plot_3? Isn't the resulting object empty? Why use the set up chunks at all? -->

Our graph is looking good, but the very long legend title takes up a lot of space. To fix this problem (and to improve the colors of the graph), add a `scale_color_brewer()` function with the "Spectral" palette as well as a `scale_linetype` function. Use **both** scale functions to set the name of the legend to "education."

```{r nes16-setup}
nes_subset <- nes %>%
  select(c(year, education, pres_appr, voted)) %>%
  filter(education %in% c("Some Highschool", "Highschool", "Some College", "Adv. Degree")) %>%
  droplevels() %>%
  mutate(opinion = as.factor(if_else(condition = str_detect(pres_appr, "prove"),
                                     true = "has_opinion",
                                     false = "no_opinion"))) %>%
  drop_na(education, opinion) %>%
  group_by(year, voted, opinion, education) %>%
  summarize(count = n()) %>%
  pivot_wider(names_from = voted, values_from = count) %>%
  mutate(turnout = Yes / (Yes + No)) 

nes_plot_3 <- ggplot(mapping = aes(x = year, 
                                   y = turnout, 
                                   color = fct_reorder2(education, year, 
                                                        turnout, .fun = first2), 
                                   linetype = fct_reorder2(education, year, turnout, 
                                                           .fun = first2))) +
    geom_line() +
    facet_wrap(~ opinion)
```

```{r nes16, exercise = TRUE}

```

```{r nes16-hint-1}
# The scale_color_brewer() function should take 2 arguments, but the scale_linetype() function should only take 1.
```


### Exercise 17

Amazing work! From this graph, we see that Americans with a higher level of education tend to vote more often. Furthermore, Americans with an opinion of the president generally have higher voter turnout than Americans without an opinion of the president. Finally, pretty much 100% of Americans with an advanced decree are able to form an opinion of the president (this is why there is no Advanced Degree line in the no_opinion graph: there are too few data points in the table).

To finish your plot, use `labs()` to give the graph a title and subtitle of your choosing.

```{r nes17-setup}
nes_subset <- nes %>%
  select(c(year, education, pres_appr, voted)) %>%
  filter(education %in% c("Some Highschool", "Highschool", "Some College", "Adv. Degree")) %>%
  droplevels() %>%
  mutate(opinion = as.factor(if_else(condition = str_detect(pres_appr, "prove"),
                                     true = "has_opinion",
                                     false = "no_opinion"))) %>%
  drop_na(education, opinion) %>%
  group_by(year, voted, opinion, education) %>%
  summarize(count = n()) %>%
  pivot_wider(names_from = voted, values_from = count) %>%
  mutate(turnout = Yes / (Yes + No)) 

nes_plot_3 <- ggplot(mapping = aes(x = year, y = turnout, 
                                   color = fct_reorder2(education, year, turnout, 
                                                        .fun = first2), 
                                   linetype = fct_reorder2(education, year, turnout, 
                                                           .fun = first2))) +
    geom_line() +
    facet_wrap(~ opinion) +
    scale_color_brewer(palette = "Spectral", name = "education") +
    scale_linetype(name = "education")
```

```{r nes17, exercise = TRUE, exercise.lines = 18}

```


## Airline Safety 

### Exercise 1 

We will be focusing on the data set `airline_saftey` from the `fivethirtyeight` package. Start by taking a `glimpse` of `airline_safety`:

```{r as-1, exercise=TRUE}

```

### Exercise 2

Do you notice anything off about the `airline_saftey` data? It's untidy! Over the next few questions, we are going to fix this. Let's start by using pivoting longer. Use `pivot_longer` to pivot the columns `incidents_85_99`, `incidents_00_14`, `fatal_accidents_00_14`,`fatal_accidents_85_99`, `fatalities_00_14` and  `fatalities_85_99` into the two new columns "type_date" and "count". Call this `airline_tidy`


```{r as-2, exercise=TRUE}

```

```{r as-2-hint, eval=FALSE}
airline_tidy <- airline_safety %>%     
  pivot_longer(c(`...`, `...`, `...`,`...`, `...`, `...`), 
        names_to = "...",values_to = "...")
```

### Exercise 3

Nice! Do you see what our next step has to be? In our `type_date` column, we have data on both the type of incident and the date range in which it occurred. This should really be two columns. Let's use the `separate()` to separate `type_date` into the two columns `type` and `date`. Separate on the s_ characters by setting the `sep` argument inside of `separate()` to "s_". 

```{r as-4-setup}
airline_tidy <- airline_safety %>%     
  pivot_longer(c(`incidents_85_99`, `incidents_00_14`, `fatal_accidents_00_14`,`fatal_accidents_85_99`, `fatalities_00_14`, `fatalities_85_99`), 
        names_to = "type_date",values_to = "count")
```

```{r as-4, exercise=TRUE}


```

```{r as-4-hint, eval=FALSE}
airline_tidy <- airline_tidy %>%     
   separate(type_date, c("...", "..."), sep = "...")
```

### Exercise 4
Fantastic! Now that our data is tidy, we can get to work. `filter()` `airline_tidy` so that we narrow down our data set to data where date is "00_14", type is "incident", and count is greater than 0.

```{r as-6-setup, include=FALSE}
airline_tidy <- airline_safety %>%     
  pivot_longer(c(`incidents_85_99`, `incidents_00_14`, `fatal_accidents_00_14`,`fatal_accidents_85_99`, `fatalities_00_14`, `fatalities_85_99`), 
        names_to = "type_date",values_to = "count") %>%
  separate(type_date, c("type", "date"), sep = "s_")
```

```{r as-6, exercise=TRUE, exercise.lines=8}

```

### Exercise 5

Nice! Now use `mutate()` to create the new variable `safety_value` and set it equal to `avail_seat_km_per_week` divided by `count`

```{r as-7-setup}
airline_tidy <- airline_safety %>%     
  pivot_longer(c(`incidents_85_99`, `incidents_00_14`, `fatal_accidents_00_14`,`fatal_accidents_85_99`, `fatalities_00_14`, `fatalities_85_99`), 
        names_to = "type_date",values_to = "count") %>%
  separate(type_date, c("type", "date"), sep = "s_") %>%
  filter(date == "00_14", count > 0)
```

```{r as-7, exercise=TRUE}


```

### Exercise 6

Nice! Now arrange `airline_tidy` by `safety_value`

```{r as-8-setup}
airline_tidy <- airline_safety %>%     
  pivot_longer(c(`incidents_85_99`, `incidents_00_14`, `fatal_accidents_00_14`,`fatal_accidents_85_99`, `fatalities_00_14`, `fatalities_85_99`), 
        names_to = "type_date",values_to = "count") %>%
  separate(type_date, c("type", "date"), sep = "s_") %>%
  filter(date == "00_14", count > 0) %>%
  mutate(safety_value = avail_seat_km_per_week / count)
```

```{r as-8, exercise=TRUE}



```

### Exercise 7

Great! Let's now use our wrangled data to create a bar plot using `geom_col()` with `airline` on the x axis and `safety_value` on the y axis. Call it `as_plot`. 

```{r as-9-setup}
airline_tidy <- airline_safety %>%     
  pivot_longer(c(`incidents_85_99`, `incidents_00_14`, `fatal_accidents_00_14`,`fatal_accidents_85_99`, `fatalities_00_14`, `fatalities_85_99`), 
        names_to = "type_date",values_to = "count") %>%
  separate(type_date, c("type", "date"), sep = "s_") %>%
  filter(date == "00_14", count > 0) %>%
  mutate(safety_value = avail_seat_km_per_week / count) %>%
  arrange(safety_value)
```

```{r as-9, exercise=TRUE, exercise.lines=10}



```

### Exercise 8

Awesome! As you can see, the airline names on the y axis are crowded and basically impossible to read. Let's change this by using theme() and setting the x axis text size to 5 and angle to 90.

```{r as-10-setup}
airline_tidy <- airline_safety %>%     
  pivot_longer(c(`incidents_85_99`, `incidents_00_14`, `fatal_accidents_00_14`,`fatal_accidents_85_99`, `fatalities_00_14`, `fatalities_85_99`), 
        names_to = "type_date",values_to = "count") %>%
  separate(type_date, c("type", "date"), sep = "s_") %>%
  filter(date == "00_14", count > 0) %>%
  mutate(safety_value = avail_seat_km_per_week / count) %>%
  arrange(safety_value)

as_plot <- ggplot(data = airline_tidy, aes(x = airline, y = safety_value)) +
  geom_col()

```

```{r as-10, exercise=TRUE}



```

```{r as-10-hint, eval=FALSE}
as_plot <- as_plot +
  theme(... = element_text(...,...))

```

### Exercise 9
Great! Now add some labels to finish our plot off!

```{r as-11-setup}
airline_tidy <- airline_safety %>%     
  pivot_longer(c(`incidents_85_99`, `incidents_00_14`, `fatal_accidents_00_14`,`fatal_accidents_85_99`, `fatalities_00_14`, `fatalities_85_99`), 
        names_to = "type_date",values_to = "count") %>%
  separate(type_date, c("type", "date"), sep = "s_") %>%
  filter(date == "00_14", count > 0) %>%
  mutate(safety_value = avail_seat_km_per_week / count) %>%
  arrange(safety_value)

as_plot <- ggplot(data = airline_tidy, aes(x = airline, y = safety_value)) +
  geom_col() + 
  theme(axis.text = element_text(size = 5, angle = 90))
```

```{r as-11, exercise=TRUE, exercise.lines=10}



```

## Partisan Lean District

### Exercise 1

We will be focusing on the data set `partisan_lean_district`, from the `fivethirtyeight` package. This data set includes the data which five thirty eight uses for their political projections.  Let's start by using the `skim()` function on `partisan_lean_district`

```{r pld-1, exercise=TRUE, exercise.lines=10}

```

### Exercise 2

Great! Now `filter()` `partisan_lean_district` so that `pvi_party` equals R. Call this `pld_subset`. 
```{r pld-2, exercise=TRUE}

```

### Exercise 3

Now select `pvi_amount` from `pld_subset`.

```{r pld-3-setup}
pld_subset <- partisan_lean_district %>% 
  filter(pvi_party == "R")
```

```{r pld-3, exercise=TRUE}



```


### Exercise 4

Fantastic! Now use `summarize()` to calculate the mean and standard deviation of the `pvi_amount` column.
```{r pld-4-setup}
pld_subset <- partisan_lean_district %>% 
  filter(pvi_party == "R") %>%
  select(pvi_amount)
```

```{r pld-4, exercise=TRUE, eval=FALSE}
  
```

```{r pld-4-hint, eval=FALSE}
pld_subset <- pld_subset %>%
  summarize(mean = mean(...), std_dev = sd(...))
```

### Exercise 5

For these next few questions, we will be using `rnorm`. Start by using `rnorm` to create a set of 241 observations with a mean of 23.2 and a standard deviation of 14.5. 

```{r pld-5-setup}
pld_subset <- partisan_lean_district %>% 
  filter(pvi_party == "R") %>%
  select(pvi_amount) %>%
  summarize(mean = mean(pvi_amount), std_dev = sd(pvi_amount))
```

```{r pld-5, exercise=TRUE, eval=FALSE}
   


```

```{r pld-5-hint, eval=FALSE}
rnorm(n = ..., mean = ..., sd = ...)
```

### Exercise 6

Now use the `tibble()` function to turn our previous set of `rnorm()` observations into a data frame, and name this dataframe `pld_nd`

```{r pld-6, exercise=TRUE, eval=FALSE, exercise.lines=10}


```

```{r pld-6-hint, eval=FALSE}
...  <- ...(value = rnorm(n = ..., mean = ..., sd = ...))
```

### Exercise 7

Awesome! Now use our newly made data frame `pld_nd` to make a histogram.Call it `nd_plot`.

```{r pld-7-setup}
pld_nd <- tibble(value = rnorm(n = 241, mean = 23.2, sd = 14.5))
```

```{r pld-7, exercise=TRUE, eval=FALSE}

```

```{r pld-7-hint, eval=FALSE}
nd_plot <- ggplot(data = ..., aes(x = ...)) + 
  geom_histogram()
```

### Exercise 8

Now, remake the plot and set the `fill` argument  to "red", the `alpha` argument to .2, and the `bins` argument set to 10.
```{r pld-8-setup}
pld_nd <- tibble(value = rnorm(n = 241, mean = 23.2, sd = 14.5))
```

```{r pld-8, exercise=TRUE, eval=FALSE, exercise.lines=10}


```

```{r pld-8-hint, eval=FALSE}
nd_plot <- ggplot(data = ..., aes(x = ...)) + 
  geom_histogram(fill = ..., alpha = ..., bins = ...)
```

### Exercise 9

Nice! Let's now make a histogram with our filtered `pld_subset` data from earlier. We've taken the liberty of removing the final `summarize()` function from `pld_subset`. Put `pvi_amount` on the x axis, and call this plot `pld_plot`. 

```{r pld-9-setup}
pld_subset <- partisan_lean_district %>% 
  filter(pvi_party == "R") %>%
  select(pvi_amount)
```

```{r pld-9, exercise=TRUE}


```

```{r pld-9-hint, eval=FALSE}
pld_plot <- ggplot(data = ..., mapping = aes(x = ...)) + 
  geom_histogram()
```

### Exercise 10

Now set the `fill` argument to "blue", the `alpha` argument to 0.2,  and the `bins` argument to 10
```{r pld-10-setup}
pld_subset <- partisan_lean_district %>% 
  filter(pvi_party == "R") %>%
  arrange(pvi_amount)
```

```{r pld-10, exercise=TRUE, eval=FALSE, exercise.lines=10}


```

```{r pld-10-hint, eval=FALSE}
pld_plot <- ggplot(data = ..., mapping = aes(x = ...)) + 
  geom_histogram(fill = ..., alpha = ..., bins = ....)
```


<!-- ## Media Mentions -->

<!-- DK: More sloppiness. matched_stores does not seem to exist and yet is used in a join. -->

<!-- ### Exercise -->

<!-- We are going to be looking at two different data sets, `media_mentions_cable` (as the tutorial name implies), and `media_mentions_online`  both from the package `fivethirtyeight`. These two data sets include data on media mentions of different candidates in the 2020 elections. Throughout the tutorial, you will need to copy, paste and pipe your code from the previous question, as we will be taking consecutive steps to wrangle our data. Let's start by taking a glimpse of both `media_mentions_cable` and `media_mentions_online`. -->

<!-- ```{r mmc-1, exercise=TRUE} -->


<!-- ``` -->

<!-- ### Exercise 2 -->

<!-- Great! Now use the `left_join` function to join the two data sets `media_mentions_cable` and `media_mentions_online` by `date` and `name`. Call this joined dataset `media_joined` -->
<!-- ```{r mmc-2, exercise=TRUE} -->


<!-- ``` -->

<!-- ```{r mmc-2-hint, eval=FALSE} -->
<!-- left_join(x = ..., y = ..., by = c("...", "...")) -->
<!-- ``` -->

<!-- ### Exercise 3 -->

<!-- Now `select()` `date`, `name`, `matched_clips`, `all_candidate_clips`, `matched_stories` and `all_ candidate_stories` -->

<!-- ```{r mmc-3-setup} -->
<!-- media_joined <- left_join(x = media_mentions_cable,  -->
<!--                           y = media_mentions_online,  -->
<!--                           by = c("date", "name")) -->
<!-- ``` -->

<!-- ```{r mmc-3, exercise=TRUE, eval=FALSE, exercise.lines=6} -->


<!-- ``` -->

<!-- ### Exercise 4 -->

<!-- Now use `mutate()` on our joined data create the new variable `matched_total` which is equal to `matched_clips` plus `matched_stories` -->

<!-- ```{r mmc-4-setup} -->
<!-- media_joined <- left_join(x = media_mentions_cable,  -->
<!--                           y = media_mentions_online,  -->
<!--                           by = c("date", "name")) %>% -->
<!--   select(date, name, matched_clips, all_candidate_clips, matched_stores, all_candidate_stories) -->
<!-- ``` -->

<!-- ```{r mmc-4, exercise=TRUE, eval=FALSE} -->


<!-- ``` -->

<!-- ### Exercise 5 -->

<!-- Nice! Now use `mutate` again to create the new variable `all_candidate_total` which is equal to `all_candidate_clips` plus `all_candidate_stories` -->

<!-- ```{r mmc-5-setup} -->
<!-- media_joined <- left_join(x = media_mentions_cable,  -->
<!--                           y = media_mentions_online,  -->
<!--                           by = c("date", "name")) %>% -->
<!--   select(date, name, matched_clips, all_candidate_clips, matched_stories, all_candidate_stories) %>% -->
<!--   mutate(matched_total = matched_stories + matched_clips) -->
<!-- ``` -->

<!-- ```{r mmc-5, exercise=TRUE} -->


<!-- ``` -->


<!-- ### Exercise 6 -->

<!-- Awesome! Now `filter()` `media_joined` to only include rows where `name` == "Julian Castro" -->
<!-- ```{r mmc-6-setup} -->
<!-- media_joined <- left_join(x = media_mentions_cable,  -->
<!--                           y = media_mentions_online,  -->
<!--                           by = c("date", "name")) %>% -->
<!--   select(date, name, matched_clips, all_candidate_clips, matched_stories, all_candidate_stories) %>% -->
<!--   mutate(matched_total = matched_stories + matched_clips) %>% -->
<!--   mutate(all_candidate_total = (all_candidate_clips + all_candidate_stories)) -->
<!-- ``` -->

<!-- ```{r mmc-6, exercise=TRUE, eval=FALSE, exercise.lines=8} -->


<!-- ``` -->

<!-- ### Exercise 7 -->

<!-- Now, let's use our filtered version of `media_joined` to make a plot! Use `geom_line()` to create a line graph with `date` on the x axis and `total_matched` on the y axis. Call this graph `media_plot`. -->

<!-- ```{r mmc-7-setup} -->
<!-- media_joined <- left_join(media_mentions_cable,media_mentions_online,c("date", "name")) %>% -->
<!--   mutate(total_matched = (matched_clips + matched_stories)) %>% -->
<!--   mutate(all_candidate_total = (all_candidate_clips + all_candidate_stories)) %>% -->
<!--   filter(name == "Julian Castro") -->
<!-- ``` -->

<!-- ```{r mmc-7, exercise=TRUE} -->


<!-- ``` -->

<!-- ```{r mmc-7-hint, eval=FALSE} -->
<!-- media_plot <- ... %>% -->
<!--   ggplot(aes(x = , y = ...)) + -->
<!--   geom_line() -->
<!-- ``` -->


<!-- ### Exercise 8 -->

<!-- Nice! As you can see, adding the second second geom changed our scale and made it harder to see trends in the first. For our final question, try changing the scale on the y axis to log base 10 -->

<!-- ```{r mmc-8-setup} -->
<!-- media_joined <- left_join(media_mentions_cable,media_mentions_online,c("date", "name")) %>% -->
<!--   mutate(total_matched = (matched_clips + matched_stories)) %>% -->
<!--   mutate(all_candidate_total = (all_candidate_clips + all_candidate_stories)) %>% -->
<!--   filter(name == "Julian Castro") -->

<!-- media_plot <- media_joined %>% -->
<!--   ggplot(aes(x = date, y = total_matched)) + -->
<!--   geom_line() -->
<!-- ``` -->

<!-- ```{r mmc-8, exercise=TRUE} -->


<!-- ``` -->

<!-- ```{r mmc-8-hint, eval=FALSE} -->
<!-- # Use scale_y_log10() -->

<!-- ``` -->

## State Words

### Exercise 1

`state_words` is a data set from the `fivethirtyeight` package. The data set includes data on phrases repeated in speeches made by governors across the United States. Let's get started by using the `skim()` function on `state_words`

```{r sw-1, exercise=TRUE}


```

### Exercise 2 

Nice! Now `filter()` `state_words` to only include rows where `category` is NOT equal to "NA". Then use the assignment operator `<-` to name this filtered data set `state_words_1`

```{r sw-2, exercise=TRUE}


```

### Exercise 3

```{r sw-3-setup}
state_words_1 <- state_words %>%
  filter(category != "NA")
```
For the next few questions, we will be focusing on factors. Run the `levels()` function on the `category` factor of data set `state_words_1`.

```{r sw-3, exercise=TRUE}


```

```{r sw-3-hint}
# Consider using the $ operator.
```

### Exercise 4

Now use the `count()` function on `category` to create a frequency table.

```{r sw-4, exercise=TRUE, exercise.setup = "sw-3-setup"}


```


### Exercise 5

Use `fct_reorder()` to reorder the factor levels in `state_words_1` by the mean of `d_speeches`. Then,  use the `levels()` function to take a look at what we have just done

```{r sw-5, exercise=TRUE, exercise.setup = "sw-3-setup"}


```

```{r sw-5-hint, eval=FALSE}
# Consider using the $ operator
```

### Exercise 6

Great! Now try using `fct_recode()` to recode the layer "economy/fiscal issues" of the factor `category` in `state_words_1` to be "economic/fiscal". Then use the `levels()` function on `state_words_1` to take a look at what we have just done

```{r sw-6, exercise=TRUE, exercise.setup = "sw-3-setup"}


```

### Exercise 7

Let's now use our data to make a plot. (You won't need to use the previous two exercises for this plot). Use the data set `state_words_1` and `geom_col()` to make a bar graph with `category` on the x axis and `d_speeches` on the y axis. Call this plot `state_words_plot`.

```{r sw-7, exercise=TRUE, eval=FALSE, exercise.setup = "sw-3-setup"}


```

### Exercise 8

Great! Remember the practice we did on questions 5 and 6? It should come in handy now! Use `fct_recode()` to recode the `category` factor on our x axis so that the layer "economy/fiscal issues" becomes "economic/fiscal". Call this plot `state_plot_2`. 


```{r sw-8, exercise=TRUE, eval=FALSE, exercise.setup = "sw-3-setup"}


```

```{r sw-8-hint, eval=FALSE}
state_plot_2 <- state_words_1 %>%
  ggplot(aes(x = (...  %>% fct_recode( ... = ...)) , y = d_speeches)) +
      geom_col()
```

### Exercise 9

Awesome! Let's add some labels and a title to finish off our plot! Add the labels "key phrase categories" and "speeches" to the x and y axes respectively, then add the title "Democratic Governor Talking Points"

```{r sw-9-setup}
state_words_1 <- state_words %>%
  filter(category != "NA") 
state_plot_2 <- state_words_1 %>%
  ggplot(aes(x = (state_words_1$category  %>% fct_recode("economic/fiscal" = "economy/fiscal issues")) , y = d_speeches)) +
      geom_col()
```

```{r sw-9, exercise=TRUE}


```

```{r sw-9-hint, eval=FALSE}
# use labs()
```

## Mediacloud 

### Exercise 1

We are going to be looking at two different data sets, `mediacloud_hurricanes` and `mediacloud_states`  (both from the package `fivethirtyeight`). These two data sets include data on the number of sentences in online media which include mentions of key words related to hurricanes in 2017.  Let's start by using the skim function on both `mediacloud_hurricanes` and `mediacloud_states` to see what we are dealing with

```{r mch-1, exercise=TRUE}

```


### Exercise 2

Great! Let's get to work. Use `left_join()` to join `mediacloud_hurricanes` and `mediacloud_states` by `date`. 

```{r mch-2, exercise=TRUE}

```

### Exercise 3

Nice! Try using `right_join()` to join `mediacloud_hurricanes` and `mediacloud_states` by `date`. How does this change the tibble?

```{r mch-3, exercise=TRUE}

```


### Exercise 4

Cool! Now use the assignment operator `<-` to name our new left joined tibble `mediacloud_combined`. 

```{r mch-4, exercise=TRUE}

```

### Exercise 5

```{r mch-5-setup}
mediacloud_combined <- left_join(mediacloud_hurricanes, mediacloud_states,"date")
```

Use `pivot_longer()` to pivot the columns `harvey`, `irma`, `maria`, `jose`, `texas`, `puerto_rico` and `florida` in `mediacloud_combined`. Put their names into a new column called "word" and their values into a new column called "mentions". 

```{r mch-5, exercise=TRUE}

```

```{r mch-5-hint, eval=FALSE}
mediacloud_combined %>% pivot_longer(..., names_to = "...", values_to = "...")
```

### Exercise 6

Awesome! Now, just like we did when we joined, use the assignment operator `<-` to name our new pivoted tibble `mediacloud_combined_tidy`. 

```{r mch-6, exercise=TRUE, exercise.setup = "mch-5-setup"}

```


### Exercise 7

```{r mch-7-setup}
mediacloud_combined <- left_join(mediacloud_hurricanes, mediacloud_states,"date")

mediacloud_combined_tidy <- mediacloud_combined %>% pivot_longer(c(`harvey`, `irma`, `maria`, `jose`, `texas`, `puerto_rico`, `florida`), names_to = "word", values_to = "mentions")
```

Nice! Now, let's use our wrangled data to make a plot! Use `geom_line()` to make a line graph with `date` on the x axis and `mentions` on the y axis. Call this plot `mediacloud_plot`. 

```{r mch-7, exercise=TRUE}

```

### Exercise 8

Hmmm, that plot isn't very useful. Copy your code from the last question, and try setting the `color` aesthetic to `word`

```{r mch-8-setup}
mediacloud_combined <- left_join(mediacloud_hurricanes, mediacloud_states,"date")

mediacloud_combined_tidy <- mediacloud_combined %>% pivot_longer(c(`harvey`, `irma`, `maria`, `jose`, `texas`, `puerto_rico`, `florida`), names_to = "word", values_to = "mentions")
```


```{r mch-8, exercise=TRUE}

```

```{r mch-8-hint, eval=FALSE}
# Because color is an aesthetic, set it inside of aes()
```

### Exercise 9

Much better! Let's finish up our plot by adding a title of your choice with a `labs()` layer.

```{r mch-9-setup}
mediacloud_combined <- left_join(mediacloud_hurricanes, mediacloud_states,"date")

mediacloud_combined_tidy <- mediacloud_combined %>% pivot_longer(c(`harvey`, `irma`, `maria`, `jose`, `texas`, `puerto_rico`, `florida`), names_to = "word", values_to = "mentions")

mediacloud_plot <- ggplot(data = mediacloud_combined_tidy, 
                          aes(x = date, y = mentions, color = word)) +
  geom_line()
```

```{r mch-9, exercise=TRUE}

```

## Unisex Names

### Exercise 1

We are going to be looking at `unisex_names`, a data set from the package `fivethirtyeight`, with data on the most popular unisex names. Let's start by taking a `glimpse()` of `unisex_names`

```{r un-1, exercise=TRUE}

  
```

### Exercise 2

For the next few questions, we will be looking at  the variable `name` and practicing our string manipulation. Start by using the `str_subset()` function to create a vector containing only names that end in a "y"

```{r un-2, exercise=TRUE}

  
```

```{r un-2-hint-1}
# Consider using the regex $
```

```{r un-2-hint-2, eval=FALSE}
str_subset(..., pattern = "...")
```

```{r un-2-hint-3, eval=FALSE}
str_subset(unisex_names$..., pattern = "...")
```

### Exercise 3

Now try doing the same thing but for names that end with "ie"

```{r un-3, exercise=TRUE}

  
```

### Exercise 4

Now use `str_sub` to create a vector with only the first three letters of each string in `name`

```{r un-4, exercise=TRUE, eval=FALSE, exercise.lines=6}

  
```

### Exercise 5

Use `mutate()` to create a column `first_letter` that uses `str_sub` to take the first letter of every name in the `name` column. 

```{r un-5, exercise=TRUE}

```

### Exercise 6

Awesome! Now use the `<-` assignment operator to save this to the new data set `unisex_names_1`.

```{r un-6, exercise=TRUE}

  
```

### Exercise 7

```{r un-7-setup}
unisex_names_1 <- unisex_names %>% 
  mutate(first_letter = str_sub(unisex_names$name, 1,1))
```

Now use `group_by()` and `summarize()` on `unisex_names_1` to create the variable `first_letter_avg`. Make `first_letter_avg` equal to the mean `total` of the names beginning with each `first_letter`[So the `first_letter_avg` for "C" should be the average number of living Americans (ie. the `total`) who have a specific name that starts with "C" which is included this data set. (This one is really confusing! Don't be afraid to look at the hint! Your resulting tibble should include two columns, one  being `first_letter_avg` and the other being `first_letter`.)]
```{r un-7, exercise=TRUE}

  
```

```{r un-7-hint-1, eval=FALSE}
unisex_names_1 %>% 
  group_by(...) %>% 
  summarize(... = mean(...))
```

### Exercise 8

Awesome! Now use the `<-` assignment operator to save this to the new data set `unisex_names_2`.

```{r un-8, exercise=TRUE, eval=FALSE, exercise.lines=6}

  
```

```{r un-8-hint, eval=FALSE}
... <- unisex_names_1 %>%
  group_by(first_letter) %>% 
  summarize(mean = mean(total))
```

### Exercise 9

```{r un-9-setup}
unisex_names_2 <- unisex_names_1 %>%
  group_by(first_letter) %>% 
  summarize(mean = mean(total))
```

Let's use our data to make a plot. Use `unisex_names_2` and `geom_col()` to make a bar graph with `first_letter` on the x axis and `first_letter_avg` on the y axis

```{r un-9, exercise=TRUE}

```

```{r un-9-hint, eval=FALSE}
  
```

## Bad Drivers

### Exercise 1

Let's do some data wrangling with the `bad_drivers` tibble from the `fivethirtyeight` package! First `skim()` the `bad_driverse` dataset.

```{r bd1, exercise=TRUE}

```

### Exercise 2

Use `select()` to remove `num_drivers`, `insurance_premiums`, and `losses` from the tibble. We can do this using the `-` operator. Call this `bd_subset`. 

```{r bd-2, exercise=TRUE}

```

### Exercise 3

You may have noticed by looking at the tibble, Use `pivot_longer` on all of the columns except for the `state` column, and then set `names_to` `type` and `values_to` `percent`.


```{r bd3-setup}
bd_subset <- bad_drivers %>% select(-c(num_drivers, insurance_premiums, losses))
```


```{r bd3, exercise=TRUE}

```

### Exercise 4

Now, we have a nice and tidy tibble. But we're not quite done yet. The first five characters in every value of our `type` column are `perc_`, which does nothing but clutter up our tibble.

Let's use `mutate()` and `str_remove()` to get rid of it.

```{r bd4-setup}
bd_subset <- bad_drivers %>% select(-c(num_drivers, insurance_premiums, losses)) %>%
  pivot_longer(cols = -state, names_to = "type", values_to = "percent")
```

```{r bd4, exercise=TRUE}

```

```{r bd4-hint}
# `mutate` our `type` variable such that we `str_remove` the `pattern` = "perc_"
```



### Exercise 5

Now, we have a neat and tidy tibble, that's much easier to manipulate. Let's say that now we want to find the 5 states that have the highest `percent` of fatal accidents linked to `alcohol`. `filter()` to choose only our rows where `type` == "alcohol".

```{r bd5-setup}
bd_subset <- bad_drivers %>% select(-c(num_drivers, insurance_premiums, losses)) %>%
  pivot_longer(cols = -state, names_to = "type", values_to = "percent") %>%
  mutate(type = str_remove(type, pattern = "perc_"))
```

```{r bd-5, exercise=TRUE}

```

### Exercise 6

Use `arrange(desc())` to sort our values in descending order of `percent`.

```{r bd6-setup}
bd_subset <- bad_drivers %>% select(-c(num_drivers, insurance_premiums, losses)) %>%
  pivot_longer(cols = -state, names_to = "type", values_to = "percent") %>%
  mutate(type = str_remove(type, pattern = "perc_")) %>%
  filter(type == "alcohol")
```

```{r bd6, exercise=TRUE}

```

### Exercise 7

Use the `head()` function to select the first `5` rows of our tibble.

```{r bd7-setup}
bd_subset <- bad_drivers %>% select(-c(num_drivers, insurance_premiums, losses)) %>%
  pivot_longer(cols = -state, names_to = "type", values_to = "percent") %>%
  mutate(type = str_remove(type, pattern = "perc_")) %>%
  filter(type == "alcohol") %>%
  arrange(desc(percent))
```

```{r bd7, exercise = TRUE}

```

### Exercise 8

Make a barplot using `ggplot()` and `geom_col()`. We'll map `x` to `state`, and y to `percent`. Call it `bd_plot`.

```{r bd8-setup}
bd_subset <- bad_drivers %>% select(-c(num_drivers, insurance_premiums, losses)) %>%
  pivot_longer(cols = -state, names_to = "type", values_to = "percent") %>%
  mutate(type = str_remove(type, pattern = "perc_")) %>%
  filter(type == "alcohol") %>%
  arrange(desc(percent)) %>%
  head(5)
```

```{r bd8, exercise = TRUE}

```

### Exercise 9

Title `bd_plot` "The Five States with the Highest Percent of Fatal Accidents from Alcohol", our x-axis "State", and our y-axis "Percent of Fatal Automobile Accidents from Alcohol".
```{r bd9-setup}
bd_subset <- bad_drivers %>% select(-c(num_drivers, insurance_premiums, losses)) %>%
  pivot_longer(cols = -state, names_to = "type", values_to = "percent") %>%
  mutate(type = str_remove(type, pattern = "perc_")) %>%
  filter(type == "alcohol") %>%
  arrange(desc(percent)) %>%
  head(5)

bd_plot <- ggplot(data = bd_subset, aes(x = state, y = percent), fill = state) + 
  geom_col() + 
  labs(title = "The Five States with the Highest Percent of Fatal Accidents from Alcohol",
       x = "State",
       y = "Percent of Fatal Automobile Accidents")
```

```{r bd9, exercise = TRUE}

```

## US_births_1994_2003

### Exercise 1

Let's do some data wrangling with the `US_births_1994_2003` tibble from the `fivthirtyeight` package. Use  `glimpse()` to get a good look at the tibble.

```{r usb1, exercise = TRUE}

```

### Exercise 2

Call on `US_births_1994_2003`, and `%>%` it into a `filter()` function. We will filter by `year` == "2000".  Call this `USB_2000`

```{r usb2, exercise=TRUE}

```

### Exercise 3

Run our filtered tibble into a `select()` function. Right now, our data is not tidy, and all the information in `month`, `date_of_month`, `year`, and `day_of_week` can be extrapolated from just `date`. We will remove the other columns to simplify our tibble. Let's select only the `date` and `births` columns.

```{r usb3-setup}
USB_2000 <- US_births_1994_2003 %>%
  filter(year == 2000) 
```

```{r usb3, exercise=TRUE}

```

### Exercise 4

Use `mutate(... = yday(...))` to create a new column for our tibble, `day_number` which will record the number of the day of year for each value in `date`.

```{r usb4-setup}
USB_2000 <- US_births_1994_2003 %>%
  filter(year == 2000) %>%
  select(date, births)
```

```{r usb4, exercise=TRUE}

```

### Exercise 5
 
Use `ggplot` and `geom_line()`, map x to `day_number` and y to `births`. Call this plot `births_plot`.

```{r usb5-setup}
USB_2000 <- US_births_1994_2003 %>%
  filter(year == 2000) %>%
  select(date, births)
```

```{r usb5, exercise=TRUE}

```

### Exercise 6

This plot is interesting, but it makes it clear that the relationship between number of births and day of the week is much greater than the relationship between number of births and the time of year. 

So let's go back to the drawing board. Why don't we instead try to find the average number of births for each week, and then create a line plot from the resulting averages.

Use `mutate(... = week(...))` to make a new column, `week_number` of `USB_2000`, that will record the number of the week of every value in `date`.

```{r usb6-setup}
USB_2000 <- US_births_1994_2003 %>%
  filter(year == 2000) %>%
  select(date, births) %>% mutate(day_number = yday(date)) %>%
  mutate(week_number = week(date))
```

```{r usb6, exercise=TRUE}

```

### Exercise 7

Use `group_by()` to group our tibble's rows by `week_number`.

```{r usb7-setup}
USB_2000 <- US_births_1994_2003 %>%
  filter(year == 2000) %>%
  select(date, births) %>% mutate(day_number = yday(date)) %>%
  mutate(week_number = week(date)) %>%
  group_by(week_number)
```

```{r usb7, exercise=TRUE}

```

### Exercise 8

Now, use `summarize()` and the `mean()` function to make yet another variable, `avg_week_births`, that number of `births` across each week. 

```{r usb8-setup}
USB_2000 <- US_births_1994_2003 %>%
  filter(year == 2000) %>%
  select(date, births) %>% mutate(day_number = yday(date)) %>%
  mutate(week_number = week(date)) %>%
  group_by(week_number) %>%
  summarize(avg_week_births = mean(births))
```

```{r usb8, exercise=TRUE}

```

### Exercise 9

Now, we're ready to make a plot again with `ggplot()` and `geom_line()`. Map x to `week_number`, and y to `avg_week_births`. Call this `births_plot_2`. 
```{r usb9-setup}
USB_2000 <- US_births_1994_2003 %>%
  filter(year == 2000) %>%
  select(date, births) %>% mutate(day_number = yday(date)) %>%
  mutate(week_number = week(date)) %>%
  group_by(week_number) %>%
  summarize(avg_week_births = mean(births))
```

```{r usb9, exercise=TRUE}

```

### Exercise 10

Now, we can finish off our plot by adding a `labs()` layer. Title our plot "Average Daily Births by Week of the Year 2000", our x-axis "Week of the Year", and our y-axis "Average Daily Births".
```{r usb10-setup}
USB_2000 <- US_births_1994_2003 %>%
  filter(year == 2000) %>%
  select(date, births) %>% mutate(day_number = yday(date)) %>%
  mutate(week_number = week(date)) %>%
  group_by(week_number) %>%
  summarize(avg_week_births = mean(births))

births_plot_2 <- ggplot(data = USB_2000, mapping = aes(x = week_number, y = avg_week_births)) +
  geom_line()
```

```{r usb10, exercise=TRUE}

```

## Daily Show Guests

### Exercise 1

Let's do some data wrangling with the `daily_show_guests` tibble from the `fivethirtyeight` tibble. Run `daily_show_guests` to get a run-down on the data in the tibble. Unlike many of the other tibbles we've worked with in this chapter, this one only contains 5 columns, so we don't need to use `glimpse()` or `skim()` to get a grasp of all the data.

Let's say that our goal with this exercise is to create a list of a few fake names that are somewhat similar, but still different to the names of popular celebrities for parody purposes.

```{r dsg1, exercise=TRUE}

```

### Exercise 2

If you notice, some of our columns have needlessly long and confusing names. 
We can tackle this with `rename()`. Let's rename our columns such that `occupation` = `google_knowledge_occupation`, and `guest` = `raw_guest_list`. Although this won't change anything about our data, it will make the tibble easier for us to work with. Call this tibble `ds_guests`.

```{r dsg2, exercise=TRUE}

```

### Exercise 3

Now, let's get wrangling. Let's `filter()` `ds_guests` our data to only contain guests whose `occupation` is "actor".

```{r dsg3-setup}
ds_guests <- daily_show_guests %>%
  rename("occupation" = google_knowledge_occupation,
         "guest" = raw_guest_list)
```

```{r dsg3, exercise=TRUE}

```

### Exercise 4

Now, suppose you wanted to pick out all of the actors whose name starts with "C". Use the `$` operator and `str_subset()` on the `guest` column of `ds_guests`. Call this atomic vector `C_guests`.  
```{r dsg4-setup}
ds_guests <- daily_show_guests %>%
  rename("occupation" = google_knowledge_occupation,
         "guest" = raw_guest_list) %>%
  filter(occupation == "actor")
```

```{r dsg4, exercise = TRUE}

```

```{r dsg4-hint}
# Consider using the regex ^ 
```


### Exercise 5

But as I'm sure you've noticed, we have quite a few duplicate names. Colin Firth alone shows up 7 times!

We can remove these duplicates using the `unique()` function. Try it on `C_guests`!


```{r dsg5-setup}
ds_guests <- daily_show_guests %>%
  rename("occupation" = google_knowledge_occupation,
         "guest" = raw_guest_list) %>%
  filter(occupation == "actor") 

C_guests <- str_subset(ds_guests$guest, pattern = "^C")
```

```{r dsg5, exercise=TRUE}

```

### Exercise 6

Much better. Now, let's go back to `str_subset()` to select only the names that contain an `r`, followed by any number of random characters before an `n`.

```{r dsg6-setup}
ds_guests <- daily_show_guests %>%
  rename("occupation" = google_knowledge_occupation,
         "guest" = raw_guest_list) %>%
  filter(occupation == "actor") 

C_guests <- str_subset(ds_guests$guest, pattern = "^C") %>%
  unique()
```

```{r dsg6, exercise=TRUE}

```

```{r dsg6-hint}
# Consider using the regex `.*`
```

### Exercise 7

Now, let's use `str_replace_all()` to change every capital letter in each name to the letter "P". This doesn't really accomplish anything productive, but I think it's kind of funny.

```{r dsg7-setup}
ds_guests <- daily_show_guests %>%
  rename("occupation" = google_knowledge_occupation,
         "guest" = raw_guest_list) %>%
  filter(occupation == "actor") 

C_guests <- str_subset(ds_guests$guest, pattern = "^C") %>%
  unique() %>%
  str_subset(., pattern = "r.*n")
```

```{r dsg7, exercise=TRUE}

```

```{r dsg7-hint}
# Consider using the regex "[A-Z]" 
```

### Exercise 8

Let's use `str_remove()` to get remove the first "i" in each name. 

Note that if we wanted to remove every "i", we could use `str_remove_all()`

```{r dsg8-setup}
ds_guests <- daily_show_guests %>%
  rename("occupation" = google_knowledge_occupation,
         "guest" = raw_guest_list) %>%
  filter(occupation == "actor") 

C_guests <- str_subset(ds_guests$guest, pattern = "^C") %>%
  unique() %>%
  str_subset(., pattern = "r.*n") %>%
  str_replace_all(., pattern = "[A-Z]", replacement = "P")
```

```{r dsg8, exercise=TRUE}

```

## Fandango

### Exercise 1

Let's do some data wrangling with the `fandango` tibble from the `fivethirtyeight` package. Run `glimpse()` on `fandango`, so we can get a grasp on all of its data.

```{r fan1, exercise=TRUE}

```

### Exercise 2

Let's begin by using `select()` to pick out the `film`, `fandango_stars`, `metacritic_norm_round`, `imdb_norm_round`, and `rt_norm_round` columns. Call this new tibble `fan_subset`

```{r fan2, exercise=TRUE}

```

### Exercise 3

Now let's use `rename()` to tidy up our variable names. Make `fandango` = `fandango_stars`, `metacritic` = `metacritic_norm_round`, `imdb` = `imdb_norm_round` and `rotten_tomatoes` = `rt_norm_round`.
```{r fan3-setup}
fan_subset <- fandango %>%
  select(film, fandango_stars, metacritic_norm_round, imdb_norm_round, rt_norm_round)
```

```{r fan3, exercise=TRUE}

```

### Exercise 5

Let's use `mutate()` to make a new column, `avg`, that's equal to the `mean()` score across all four of our columns (except for the `film` column). 
```{r fan4-setup}
fan_subset <- fandango %>%
  select(film, fandango_stars, metacritic_norm_round, imdb_norm_round, rt_norm_round) %>%
  rename("fandango" = fandango_stars,
         "metacritic" = metacritic_norm_round,
         "imdb" = imdb_norm_round,
         "rotten_tomatoes" = rt_norm_round)
```

```{r fan4, exercise=TRUE}

```

### Exercise 5

But let's say we want to make `avg` rounded to the nearest 0.5, like every other column. 

This is actually a bit tricky, because the `round()` function in R will only round to the nearest decimal place. However, we can get around it using some clever arithmetic. Once again, we're using `mutate()` because we're making a vector from a vector.

Change `avg` to be equal to `round()` of `avg * 2`, to `0` decimal places (using the `digits` argument) and then dividing the result by 2.

```{r fan5-setup}
fan_subset <- fandango %>%
  select(film, fandango_stars, metacritic_norm_round, imdb_norm_round, rt_norm_round) %>%
  rename("fandango" = fandango_stars,
         "metacritic" = metacritic_norm_round,
         "imdb" = imdb_norm_round,
         "rotten_tomatoes" = rt_norm_round) %>%
  mutate(avg = (fandango + metacritic + imdb + rotten_tomatoes) / 4)
```

```{r fan5, exercise=TRUE}

```

```{r fan5-hint, eval=FALSE}
... <- fan_subset %>%
  mutate(avg = round(x = ..., digits = ...)/2)
```

### Exercise 6

Now that we have all of our columns, we can make our data tidy using the `pivot_longer()` function. We're going to be using every column except for `film`, putting our variable names into a new column called `critic_website`, and our values into a new column called `score`.

```{r fan6-setup}
fan_subset <- fandango %>%
  select(film, fandango_stars, metacritic_norm_round, imdb_norm_round, rt_norm_round) %>%
  rename("fandango" = fandango_stars,
         "metacritic" = metacritic_norm_round,
         "imdb" = imdb_norm_round,
         "rotten_tomatoes" = rt_norm_round) %>%
  mutate(avg = (fandango + metacritic + imdb + rotten_tomatoes) / 4) %>%
  mutate(avg = round(x = avg, digits = 2) / 2)
```

```{r fan6, exercise=TRUE}

```

```{r fan6-hint, eval=FALSE}
... %>% pivot_longer(cols = -film, names_to = "...", values_to = "...")
```

### Exercise 7

Let's use our tidy data to make a boxplot with `ggplot()` `geom_boxplot()` Map x to `critic_website` and y to `score`. Call this plot `fan_plot`. 

```{r fan7-setup}
fan_subset <- fandango %>%
  select(film, fandango_stars, metacritic_norm_round, imdb_norm_round, rt_norm_round) %>%
  rename("fandango" = fandango_stars,
         "metacritic" = metacritic_norm_round,
         "imdb" = imdb_norm_round,
         "rotten_tomatoes" = rt_norm_round) %>%
  mutate(avg = (fandango + metacritic + imdb + rotten_tomatoes) / 4) %>%
  mutate(avg = round(x = avg, digits = 0) / 2) %>% 
  pivot_longer(cols = -film, names_to = "critic_website", values_to = "score")
```

```{r fan7, exercise=TRUE}

```

### Exercise 8

Let's use `theme_classic()` to change the theme of our plot.

```{r fan8-setup}
fan_subset <- fandango %>%
  select(film, fandango_stars, metacritic_norm_round, imdb_norm_round, rt_norm_round) %>%
  rename("fandango" = fandango_stars,
         "metacritic" = metacritic_norm_round,
         "imdb" = imdb_norm_round,
         "rotten_tomatoes" = rt_norm_round) %>%
  mutate(avg = (fandango + metacritic + imdb + rotten_tomatoes) / 4) %>%
  mutate(avg = round(x = avg, digits = 0) / 2) %>% 
  pivot_longer(cols = -film, names_to = "critic_website", values_to = "score")

fan_plot <- ggplot(data = fan_subset, 
                   mapping = aes(x = critic_website, y = score)) + 
  geom_boxplot()
```

```{r fan8, exercise=TRUE}

```

### Exercise 9

Good. Let's also add some labels with `labs()`. Title the plot "Average Movie Scores from Different Critic Websites", our x-axis "Critic Website", and our y-axis "Score (Out of 5)"

```{r fan9-setup}
fan_subset <- fandango %>%
  select(film, fandango_stars, metacritic_norm_round, imdb_norm_round, rt_norm_round) %>%
  rename("fandango" = fandango_stars,
         "metacritic" = metacritic_norm_round,
         "imdb" = imdb_norm_round,
         "rotten_tomatoes" = rt_norm_round) %>%
  mutate(avg = (fandango + metacritic + imdb + rotten_tomatoes) / 4) %>%
  mutate(avg = round(x = avg, digits = 0) / 2) %>% 
  pivot_longer(cols = -film, names_to = "critic_website", values_to = "score")

fan_plot <- ggplot(data = fan_subset, 
                   mapping = aes(x = critic_website, y = score)) + 
  geom_boxplot() +
  theme_classic()
```

```{r fan9, exercise=TRUE}

```

## Submit

```{r context="setup"}
submission_ui
```

```{r context="server"}
submission_server()
```

